{"pages":[{"title":"关于","text":"你好，这里是毕业Pro，本团队为专业计算机程序作业代做,CS代写,Python代做,Java代做,算法代做,程序代做,机器学习代做 mail: kefu2#biye.pro 版权申明：若没有特殊说明，文章皆是碧野原创，未经明确许可请勿转载。","link":"/about/index.html"},{"title":"tags","text":"","link":"/tags/index.html"},{"title":"categories","text":"","link":"/categories/index.html"}],"posts":[{"title":"程序代做业务介绍","text":"关于我们成员来自知名互联网公司和985高校以及中科院，根据需求可24-48小时加急完成。 付款流程：预付50%定金，全部做完后，发程序视频跟客户确认，无误后收取尾款，发送整个程序。（对于难度较大，时间较长的课题，中途可提供部分功能用于老师检查。） 代写特色 ：靠谱售后服务，包括环境配置、程序调试、程序讲解，再不加功能的基础上，进行程序修改。杜绝一手交钱一手交货然后跑路的黑心代写行为，给予客户最大的信任(信任是相互的)，毕业pro代写始终坚持诚信。 温馨提示：目前收到客户反馈的一些黑代写的行为: 骗完定金拉黑，以次充好骗余款, gif演示成功付完钱本地运行不了，弃之不顾…请大家擦亮眼睛 业务范围提供专属的CS程序代写服务，代写各类程序语言，承接各类程序代做作业，java，python，php，c++，网页web，javascript，机器学习，数据挖掘，数据分析，excel，bi，人工智能，数学题，高数，线代，算法题，ui设计，交互设计，英文翻译，论文辅导写作等等。 我们不是中介，我们是团队作业！我们不是代码的搬运工，我们每一分作业均属原创！相比于中介高昂的中介费和个人代写的不靠谱和漫天要价, 我们团队保证质量的同时, 尽量把价格做到最低, 实现同学们和团队工程师的双赢。 我们的优势 我们有经验丰富学历强大的IT一线工程师，成员来自知名互联网公司和985高校以及中科院，最快24-48小时即可完成，用技术和耐心帮助客户高效高质量提交作业。 我们价格公道，绝无高昂的中介费，都是团队自身成员直接接单。 我们可以在30分钟内准确高效的评估作业时间和难度，期中提供答疑服务，完成后可根据需求更改。 无限期售后服务，真正的一站式无忧服务。 郑重承诺【原创】代码保证原创，查重轻松过。 【高质量】是我们坚守的原则, 我们用把精力和时间花在您的作业上，而不是跟您的讨价还价上。 【诚信】在截止日期内，按照您的需求文档保质保量的完成。 【口碑】很多客户长期合作的优质代写团队。 【互相】50%的预付款，完成所有作业，验收后，再结尾款。 【承诺】代码本地run不了，全额退款。因为专业，所以自信。 【售后】所有代写服务均包括配置环境，代码调试、修改、讲解。 联系我们Email: kefu2@biye.pro 微信号: biyeprodaixie QQ号: 2422447293 为了保证我们尽快联系和评估您的作业, 请注明您的作业具体要求、时间和年级。 交易流程微信联系我们——工程师看题报价——协定作业价格，支付50%定金——客户中期可了解进度——客户验收，补齐尾款——终身售后。 报价参考：我们根据工作量、难度和时间决定价格，坚决抵制黑中介漫天要价的恶劣行为。 但是也不要低估码农们的劳动成果，毕竟一分钱一分货，you get what you pay for. 客户评价","link":"/front-end/%E7%A8%8B%E5%BA%8F%E4%BB%A3%E5%81%9A%E4%B8%9A%E5%8A%A1%E4%BB%8B%E7%BB%8D/"},{"title":"深度学习简介","text":"深度学习简介简介什么是AI？这些大惊小怪的是什么？因此，让我们从正式定义开始：它是由机器（尤其是计算机系统）对人类智能过程进行的模拟。这些过程包括学习，推理和自我纠正。但是，如果您想用一些非正式和轻松的语言来定义AI，那么：这是一种现象或任务，我们试图在其中创建可以模仿人类工作的机器，即人类的智力和逻辑。这不是几年前开始的事情，发明家们梦long以求的梦想至少是从古希腊时代起就实现了。如今，您可以在许多领域看到人工智能（AI）的应用，例如使日常工作自动化，智能手机上的面部识别和语音识别，医学诊断和科学研究等自动化的智能软件。以前，一些AI项目已寻求使用逻辑推理规则将其编码为硬编码知识，这就是所谓的人工智能知识库方法。但是可悲的是，这些项目都没有取得重大成功，因为人工操作人员不可能为机器手动定义所有规则，也不可能找出特定工作的所有可能情况，因为在现实世界中情况可能是任何事情。 机器学习最初的AI系统面临的这些困难表明，需要通过从原始数据中提取模式来获取自己的知识的能力。此功能称为机器学习。 机器学习使计算机能够获取现实生活中的原始数据或示例，并尝试从中提取模式并自行做出更好的决策。一些机器学习算法是逻辑回归，朴素贝叶斯，SVM等。这些机器学习算法的性能在很大程度上取决于给定数据的表示形式。表示中包含的每条信息都称为特征，这些算法学习如何使用这些特征来提取模式或获取知识。但是有时很难提取要提取哪些特征的信息。例如，假设我们想从图像中检测汽车，现在我们可能希望将车轮的存在作为特征。但是很难用像素值来描述轮子的外观。解决此问题的一种方法是使用机器学习不仅发现那些特征（表示）的输出，而且发现特征本身。这种方法称为表示学习。同样，如果算法能以最少的人工干预自己学习特征，那就更好了。设计这些算法时，我们的目标通常是分离变化因素。现在这些因素并不总是直接被观察到，它们可能是未被观察到的因素，也会影响我们的算法。现在，当然，要从语音识别的说话人口音等原始数据中提取高级抽象特征可能很困难，因为只有通过对数据的人为理解才能识别出这些特征。 深度学习深度学习可以通过引入以其他更简单的表示形式表示的表示形式，来解决表示学习中的这一问题。 我认为以上引用非常适合深度学习的工作方式，它使您可以从较简单的概念中构建出复杂的概念。 为了更“深入”地理解它，我们举一个例子： 上图是深度学习模型的图示。如前所述，算法本身很难理解原始输入数据，因此深度学习通过将输入（映射）分解为更简单的形式（模型的每一层都对其进行描述）来解决该问题。如您在上图中所见，共有五层，并且它们彼此互连。如果对这些层进行分类，则在上图中，我们将有一个输入层，一个输出层和三个隐藏层（可以改变）。输入显示在可见层（输入层），我们能够观察到它，这解释了名称。然后，一系列的隐藏层（未提供此数据，这就是为什么被称为“隐藏”）越来越多地提取抽象特征。稍后我们将讨论“越来越多”的部分。最后，我们有了代表模型输出的输出层。现在，对于“越来越多”的部分，隐藏层负责提取特征，并说第一个隐藏层负责识别输入图像中的边缘。如果该第二层可以轻松地搜索延伸轮廓的拐角，并且类似地使用第二层，则第三层可以检测特定对象的整个部分，这也可以解释这些层的互连性。 历史趋势您应该知道深度学习不是一项新技术，这一事实可以追溯到1940年代。但是它似乎是新的，因为它几年来一直不受欢迎，这就是为什么我们将研究一些历史事实和趋势以了解其起源。出现了三波发展浪潮：称为控制论的深度学习（1940年代至1960年代），称为连接主义的深度学习（1980年代至1990年代）和以深度学习为名的当前浪潮（2006年至今）。第一波控制论始于生物学学习理论的发展和诸如感知器之类的第一个模型的实施，从而能够训练单个神经元。第二波浪潮是从带有反向传播的连接主义方法开始的，以训练具有一个或两个隐藏层的神经网络。当前和第三次浪潮始于2006年左右（Hinton等，2006； Bengio等，2007； Ranzato等，2007a），我们将在本系列的后续部分中进行详细讨论。 为什么深度学习现在变得流行？正如我之前提到的，深度学习可以追溯到1940年代，但是最近开始流行，并且吸引了许多研究人员和工程师的眼球。 但是随之而来的问题是为什么现在呢？ 这个问题的答案隐藏在深度学习模型的“隐藏层”中。 您之前已经看到深度学习模型（神经网络）包含层，并且要解决特定（大）问题，它需要许多层，这又需要更大的数据集，而要处理更大的数据集，我们需要更多的处理能力和更多的东西。 让我们详细讨论一下： 增加数据集大小：深度学习自1990年代以来就开始应用，但当时很多研究人员拒绝使用它，因为要使其完美工作并获得更好的结果，人们需要一个庞大的数据集，该数据集可以馈入网络，以便隐藏层可以从中提取每个抽象特征。 但是，这一切都随着社会数字化的增加而开始改变，越来越多的活动在计算机上发生，在网络中连接在一起的计算机也在增加，等等。 “大数据”时代已经使深度学习的实施变得更加容易和有效。 增加的模型体积：神经网络成功的另一个关键原因是具有更大内存的更快计算机的发展。 在拥有更大的数据集之后，研究人员面临的另一个障碍是如何处理和存储大量数据。 但是，随着当今更快的CPU和GPU以及更大的内存，我们有足够的资源来处理更大的数据集。 提高准确性和对现实世界的影响：由于技术上的所有这些进步，研究人员现在能够大规模地进行实验，并且每天发现新的算法，概念和结果。深度学习提高了其提供更准确结果的能力，因此，它在现实生活中的使用也在增加。由于研究人员现在能够在语音识别，物体检测，图像识别等任务中获得几乎与人类相似的结果，因此许多大型IT公司现在都在其实际产品中使用深度学习。总而言之，深度学习是一种机器学习方法，它极大地利用了我们对人脑，应用数学和统计学的了解。近年来，深度学习在其受欢迎程度和实用性方面取得了巨大的增长。至此，本系列博客的第一部分结束了。我目前正在研究本系列的第二部分，我们将深入研究一些应用数学和线性代数。我将尝试尽快完成并在此处更新其链接。希望您喜欢这一部分，我们也会在接下来的部分中学习更多。","link":"/front-end/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/"},{"title":"Python AsyncIO 异步编程完全指南","text":"AsyncIO 是一种并发编程设计，已在Python中获得了专门的支持，从Python 3.4到3.7以及可能以后的版本迅速发展。 您可能会担心“并发，并行性，线程化，多处理。 已经掌握了很多东西。AsyncIO放在哪里？” 本教程旨在帮助您回答该问题，从而使您对Python的AsyncIO方法有更深入的了解。 这是要介绍的内容： 异步IO（AsyncIO）： 一种与语言无关的范例（模型），具有跨多种编程语言的实现 异步/等待： 两个新的Python关键字，用于定义协程 asyncio： Python软件包，为运行和管理协程提供了基础和API 协程（专门的生成器函数）是Python中异步IO的核心，稍后我们将深入探讨它们。 设置环境您需要Python 3.7或更高版本才能完整阅读本文，以及aiohttp和aiofiles软件包： 123$ python3.7 -m venv ./py37async$ source ./py37async/bin/activate # Windows: .\\py37async\\Scripts\\activate.bat$ pip install --upgrade pip aiohttp aiofiles # Optional: aiodns 异步IO概览比起多处理和线程处理，异步IO的相关资料要少很多。 本节将为您提供什么是异步IO以及它如何适应其周围环境的完整图谱。 异步IO用在哪里并发和并行性是不容易涉足的扩展主题。尽管本文着重介绍异步IO及其在Python中的实现，但值得花一点时间将异步IO与同类产品进行比较，以了解异步IO如何适应更大，有时令人头晕的难题。 并行性包括同时执行多个操作。多进程是一种实现并行性的方法，它需要将任务分散到计算机的中央处理单元（CPU或内核）上。多重处理非常适合CPU限制的任务：紧密结合循环和数学计算通常属于此类。 并发是比并行性稍微宽泛的术语。这表明多个任务具有以重叠方式运行的能力。 （有一种说法是并发并不意味着并行。） 线程是并发执行模型，多个线程轮流执行任务。一个进程可以包含多个线程。由于具有GIL，Python与线程之间的关系非常复杂，但这超出了本文的范围。 重要的是要知道线程化对于IO绑定的任务来说更好。尽管CPU密集型任务的特征是计算机内核从头到尾不断地努力工作，但IO受限型工作主要由大量等待输入/输出来完成。 综上所述，并发包括多处理（理想的是CPU绑定任务）和线程处理（适用于IO绑定任务）。多处理是并行性的一种形式，并行性是并发的特定类型（子集）。 Python标准库通过其多处理，线程和parallel.futures包为这两者提供了长期支持。 现在是时候让一个新成员加入了。在过去的几年中，CPython中已经更加全面地构建了一个独立的设计：异步IO，它通过标准库的asyncio包和新的async和await语言关键字启用。需要明确的是，异步IO并不是一个新发明的概念，它已经存在或正在内置到其他语言和运行时环境中，例如Go，C＃或Scala。 Python文档将asyncio软件包记为一个用于编写并发代码的库。但是，异步IO不是线程化，也不是多处理。它不是建立在这两个之上的。 实际上，异步IO是一种单线程，单进程设计：它使用协作多任务处理，这个术语您将在本教程结束时充实。换句话说，尽管在单个进程中使用单个线程，但异步IO却带来了并发的感觉。协程（异步IO的主要功能）可以并发进行调度，但是它们并不是天生并发的。 重申一下，异步IO是并发编程的一种形式，但它不是并行性。与多线程处理相比，它与线程处理的关系更加紧密，但两者却截然不同，并且是并发技巧包中的独立成员。 异步是什么意思？ 这不是一个严格的定义，但是出于我们此处的目的，我可以想到两个属性： 异步例程可以在等待其最终结果的同时“暂停”，并让其他协程同时运行。 通过上述机制，异步代码有助于并发执行。 换句话说，异步代码给出了并发的外观。 这是将所有内容放在一起的图表。 白色术语代表概念，绿色术语代表其实现或实现的方式： 我将停止并发编程模型之间的比较。 本教程的重点是异步IO的子组件，如何使用它以及围绕它兴起的API。 异步IO解释异步IO乍看起来似乎违反直觉和自相矛盾。 促进并发代码的事物如何使用单个线程和单个CPU内核？ 我从来都不擅长制作示例，所以我想解释一下Miguel Grinberg在2017年的PyCon演讲中的一个，它很好地解释了所有内容： 国际象棋大师朱迪特·波尔加尔（JuditPolgár）举办国际象棋展览，在其中她扮演多个业余玩家。 她有两种举办展览的方式：同步和异步。 假设 24个对手 Judit在5秒内使每盘棋移动 对手各花费55秒采取行动 游戏平均30对动作（总共60个动作） 同步版本：Judit一次只能玩一场游戏，决不能一次玩两局，直到游戏完成为止。 每个游戏需要（55 + 5）* 30 == 1800秒或30分钟。 整个展览需要24 * 30 == 720分钟或12个小时。 异步版本：Judit在一个表之间移动，在每个表上移动一个。 她离开桌子，让对手在等待时间内采取下一步行动。 在所有24场比赛中，一动需要Judit 24 * 5 == 120秒或2分钟。 整个展览现在缩短为120 * 30 == 3600秒，或仅1小时。 JuditPolgár只有一只，只有两只手，一次只能动一动。 但是异步播放可以将展览时间从12小时减少到一小时。 因此，协作式多任务处理是一种奇特的方式，可以说程序的事件循环（稍后会详细介绍）与多个任务进行通信，以使每个任务在最佳时间轮流运行。 异步IO需要较长的等待时间，否则功能将被阻塞，并允许其他功能在停机期间运行。 （有效阻止的功能从开始到返回为止一直禁止其他人运行。） 异步IO并不简单我听说：“尽可能使用异步IO； 必要时使用线程。” 事实是，构建持久的多线程代码可能很困难且容易出错。 异步IO避免了线程设计可能会遇到的某些潜在的速度颠簸。 但这并不是说Python中的异步IO很简单。 请注意：当您冒险进入水平面以下时，异步编程也可能会很困难！ Python的异步模型是基于诸如回调，事件，传输，协议和期货之类的概念构建的，只是术语可能令人生畏。 其API不断变化的事实使其变得不那么容易。 幸运的是，asyncio已经发展到其大部分功能不再是临时的程度，而其文档已得到了巨大的改进，与此相关的一些优质资源也开始出现。 asyncio包和async / await现在，您已经对异步IO作为设计有了一定的了解，下面让我们探讨Python的实现。 Python的asyncio程序包（在Python 3.4中引入）及其两个关键字async和await具有不同的用途，但可以一起帮助您声明，构建，执行和管理异步代码。 async/await 语法和原生协同程序异步IO的核心是协程。 协程是Python生成器函数的专用版本。 让我们从基线定义开始，然后在此处进行构建：协程是一个函数，可以在到达返回值之前暂停其执行，并且可以将控制权间接传递给另一个协程一段时间。 稍后，您将更深入地研究如何将传统生成器准确地用于协程。 目前，了解协程工作方式的最简单方法是开始制作协程。 让我们采用沉浸式方法并编写一些异步IO代码。 这个简短的程序是异步IO的Hello World，但是在说明其核心功能方面还有很长的路要走： 12345678910111213141516171819#!/usr/bin/env python3# countasync.pyimport asyncioasync def count(): print(\"One\") await asyncio.sleep(1) print(\"Two\")async def main(): await asyncio.gather(count(), count(), count())if __name__ == \"__main__\": import time s = time.perf_counter() asyncio.run(main()) elapsed = time.perf_counter() - s print(f\"{__file__} executed in {elapsed:0.2f} seconds.\") 执行此文件时，请注意与仅使用def和time.sleep（）定义函数的外观有所不同： 12345678$ python3 countasync.pyOneOneOneTwoTwoTwocountasync.py executed in 1.01 seconds. 此输出的顺序是异步IO的核心。 与count()的每个调用进行交谈都是一个事件循环或协调器。 当每个任务到达等待asyncio.sleep(1)时，该函数都会大喊事件循环并对其进行控制，并说：“我要睡一秒钟。 继续，让其他有意义的事情同时进行。” 将此与同步版本进行对比： 12345678910111213141516171819#!/usr/bin/env python3# countsync.pyimport timedef count(): print(\"One\") time.sleep(1) print(\"Two\")def main(): for _ in range(3): count()if __name__ == \"__main__\": s = time.perf_counter() main() elapsed = time.perf_counter() - s print(f\"{__file__} executed in {elapsed:0.2f} seconds.\") 当执行时，顺序和执行时间会有微小但关键的变化： 12345678$ python3 countsync.pyOneTwoOneTwoOneTwocountsync.py executed in 3.01 seconds. 虽然使用time.sleep（）和asyncio.sleep（）似乎很平庸，但它们用作涉及等待时间的所有耗时的过程的替身。 （您可以等待的最普通的事情是基本上不执行任何操作的sleep（）调用。）也就是说，time.sleep（）可以表示任何耗时的阻塞函数调用，而asyncio.sleep（）用于站立 进行非阻塞呼叫（但也需要一些时间才能完成）。 正如您将在下一节中看到的那样，等待某些内容（包括asyncio.sleep（））的好处是，周围的函数可以暂时将控制权让给另一个更容易立即执行某项功能的函数。 相反，time.sleep（）或任何其他阻塞调用与异步Python代码不兼容，因为它将在睡眠时间内停止轨道中的所有内容。 异步IO规则此时，对async，await和它们创建的协程函数的更正式定义是有序的。 这部分内容比较繁琐，但是掌握异步/等待功能是有帮助的，因此，如果需要，请返回至此： 语法async def引入了本机协程或异步生成器。 与和异步的表达式也有效，稍后您将看到它们。 关键字await将功能控制传递回事件循环。 （它暂停了周围协程的执行。）如果Python在g（）范围内遇到await f（）表达式，这就是await告诉事件循环的方式，“暂停g（）的执行，直到我等待的是 返回f（）的结果。 同时，让其他东西运行。” 在代码中，第二个要点大致如下所示： 1234async def g(): # Pause here and come back to g() when f() is ready r = await f() return r 关于何时以及如何以及不可以使用异步/等待，还有一套严格的规则。无论您仍是语法还是已经使用async / await，这些都可以很方便： 您使用async def引入的功能是协程。它可以使用await，return或yield，但是所有这些都是可选的。声明异步def noop（）：pass有效： 使用等待和/或返回将创建协程函数。要调用协程函数，必须等待它以获得结果。 在异步def块中使用yield的情况不太普遍（并且只有最近才在Python中合法）。这将创建一个异步生成器，您可以使用异步生成器对其进行迭代。暂时不要使用异步生成器，而将重点放在获取协程函数的语法上，协程函数使用等待和/或返回。 用async def定义的任何内容都可能不使用yield from，这将引发SyntaxError。 就像在def函数之外使用yield的SyntaxError一样，在异步def协程之外使用await也是SyntaxError。您只能在协程体内使用await。 以下是一些简短的示例，旨在总结上述几条规则： 12345678910111213async def f(x): y = await z(x) # OK - `await` and `return` allowed in coroutines return yasync def g(x): yield x # OK - this is an async generatorasync def m(x): yield from gen(x) # No - SyntaxErrordef m(x): y = await z(x) # Still no - SyntaxError (no `async def` here) return y 最后，当您使用await f（）时，要求f（）是可等待的对象。 好吧，那不是很有帮助，是吗？ 现在，只知道一个可等待的对象是（1）另一个协程或（2）定义返回迭代器的.__ await __（）dunder方法的对象。 如果您正在编写程序，则出于大多数目的，您只需要担心案例1。 这给我们带来了另一个可能会弹出的技术区别：将函数标记为协程的一种较旧的方法是用@ asyncio.coroutine装饰一个普通的def函数。 结果是基于生成器的协程。 自从在Python 3.5中使用async / await语法以来，这种构造已经过时了。 这两个协程在本质上是等效的（都可以等待），但是第一个协程基于生成器，而第二个是本地协程： 12345678910import asyncio@asyncio.coroutinedef py34_coro(): \"\"\"Generator-based coroutine, older syntax\"\"\" yield from stuff()async def py35_coro(): \"\"\"Native coroutine, modern syntax\"\"\" await stuff() 如果您自己编写任何代码，则最好使用本机协程，以使其显式而不是隐式。基于生成器的协程将在Python 3.10中删除。 在本教程的后半部分，我们将仅出于说明的目的触及基于生成器的协程。引入异步/等待的原因是为了使协程成为Python的独立功能，可以很容易地将其与普通的生成器函数区分开，从而减少了歧义。 不要陷入基于发电机的协程中，这些协程已经被异步/等待故意地过时了。它们有自己的一小套规则（例如，不能在基于生成器的协程中使用await），如果您坚持使用async / await语法，则这些规则在很大程度上是不相关的。 事不宜迟，让我们举一些更多的例子。 这是异步IO如何减少等待时间的一个示例：给定一个协程makerandom（），该协程不断产生范围为[0，10]的随机整数，直到其中一个超过阈值为止，您要让该协程多次调用不需要等待彼此相继完成。您可以在很大程度上遵循上述两个脚本的模式，并稍作更改： 123456789101112131415161718192021222324252627282930313233#!/usr/bin/env python3# rand.pyimport asyncioimport random# ANSI colorsc = ( \"\\033[0m\", # End of color \"\\033[36m\", # Cyan \"\\033[91m\", # Red \"\\033[35m\", # Magenta)async def makerandom(idx: int, threshold: int = 6) -&gt; int: print(c[idx + 1] + f\"Initiated makerandom({idx}).\") i = random.randint(0, 10) while i &lt;= threshold: print(c[idx + 1] + f\"makerandom({idx}) == {i} too low; retrying.\") await asyncio.sleep(idx + 1) i = random.randint(0, 10) print(c[idx + 1] + f\"---&gt; Finished: makerandom({idx}) == {i}\" + c[0]) return iasync def main(): res = await asyncio.gather(*(makerandom(i, 10 - i - 1) for i in range(3))) return resif __name__ == \"__main__\": random.seed(444) r1, r2, r3 = asyncio.run(main()) print() print(f\"r1: {r1}, r2: {r2}, r3: {r3}\") 如图所示： 该程序使用一个主要协程makemakerandom（），并在3个不同的输入上同时运行它。大多数程序将包含小型模块化协程和一个包装器功能，用于将每个较小的协程链接在一起。 main（）然后用于通过在一些可迭代或池中映射中央协程来收集任务（未来）。 在此微型示例中，池为range（3）。在稍后提供的完整示例中，它是需要同时请求，解析和处理的一组URL，并且main（）为每个URL封装整个例程。 尽管“制作随机整数”（比CPU绑定更多的东西）可能不是asyncio的最佳选择，但在示例中正是asyncio.sleep（）的存在旨在模仿IO绑定的过程等待时间不确定的地方。例如，asyncio.sleep（）调用可能表示消息应用程序中两个客户端之间发送和接收非随机整数。 异步IO设计模式异步IO带有自己的一组可能的脚本设计，本节将介绍它们。 链协程协程的一个关键特征是它们可以链接在一起。 （请记住，一个协程对象是可以等待的，因此另一个协程可以等待它。）这使您可以将程序分解为较小的，可管理的，可回收的协程： 12345678910111213141516171819202122232425262728293031323334353637383940# chained.pyimport asyncioimport randomimport timeasync def part1(n: int) -&gt; str: i = random.randint(0, 10) print(f\"part1({n}) sleeping for {i} seconds.\") await asyncio.sleep(i) result = f\"result{n}-1\" print(f\"Returning part1({n}) == {result}.\") return resultasync def part2(n: int, arg: str) -&gt; str: i = random.randint(0, 10) print(f\"part2{n, arg} sleeping for {i} seconds.\") await asyncio.sleep(i) result = f\"result{n}-2 derived from {arg}\" print(f\"Returning part2{n, arg} == {result}.\") return resultasync def chain(n: int) -&gt; None: start = time.perf_counter() p1 = await part1(n) p2 = await part2(n, p1) end = time.perf_counter() - start print(f\"--&gt;Chained result{n} =&gt; {p2} (took {end:0.2f} seconds).\")async def main(*args): await asyncio.gather(*(chain(n) for n in args))if __name__ == \"__main__\": import sys random.seed(444) args = [1, 2, 3] if len(sys.argv) == 1 else map(int, sys.argv[1:]) start = time.perf_counter() asyncio.run(main(*args)) end = time.perf_counter() - start print(f\"Program finished in {end:0.2f} seconds.\") 注意输出，part1（）睡眠一段可变的时间，part2（）在结果可用时开始处理它们： 1234567891011121314151617$ python3 chained.py 9 6 3part1(9) sleeping for 4 seconds.part1(6) sleeping for 4 seconds.part1(3) sleeping for 0 seconds.Returning part1(3) == result3-1.part2(3, 'result3-1') sleeping for 4 seconds.Returning part1(9) == result9-1.part2(9, 'result9-1') sleeping for 7 seconds.Returning part1(6) == result6-1.part2(6, 'result6-1') sleeping for 4 seconds.Returning part2(3, 'result3-1') == result3-2 derived from result3-1.--&gt;Chained result3 =&gt; result3-2 derived from result3-1 (took 4.00 seconds).Returning part2(6, 'result6-1') == result6-2 derived from result6-1.--&gt;Chained result6 =&gt; result6-2 derived from result6-1 (took 8.01 seconds).Returning part2(9, 'result9-1') == result9-2 derived from result9-1.--&gt;Chained result9 =&gt; result9-2 derived from result9-1 (took 11.01 seconds).Program finished in 11.01 seconds. 在此设置中，main（）的运行时间将等于它收集在一起并计划的任务的最大运行时间。 使用队列asyncio软件包提供的队列类旨在与队列模块的类相似。到目前为止，在我们的示例中，我们实际上并不需要队列结构。在chained.py中，每个任务（未来）都由一组协程组成，这些协程明确地相互等待，并通过每条链上的单个输入。 还有一种可以与异步IO一起使用的替代结构：彼此不相关的许多生产者将项目添加到队列中。每个生产者可以在交错，随机，未通知的时间将多个项目添加到队列中。一群消费者在贪婪地出现时将它们从队列中拉出，而不必等待任何其他信号。 在这种设计中，没有任何个人消费者链接到生产者。消费者不知道生产者的数量，甚至不知道将要添加到队列中的项目的累计数量。 每个生产者或消费者花费可变的时间分别从队列中放入和提取项目。队列用作可以与生产者和消费者进行通信的吞吐量，而无需他们彼此直接交谈。 注意：尽管由于queue.Queue（）的线程安全性，所以队列经常在线程程序中使用，但异步IO时您不必担心线程安全。 （当您将两者结合在一起时是个例外，但是本教程中没有这样做。） 队列的一个用例（如此处的情况）是队列充当生产者和消费者的发送者，而这些生产者和消费者在其他情况下并没有直接链接或关联。 该程序的同步版本看起来非常令人沮丧：一组阻塞的生产者将项目串行添加到队列中，一次添加一个生产者。只有在所有生产者都完成之后，才能由一个消费者逐项处理队列。此设计存在大量延迟。物品可能闲置地排在队列中，而不是立即拿起并处理。 下面是一个异步版本asyncq.py。此工作流程中具有挑战性的部分是，需要向消费者发出生产已完成的信号。否则，await q.get（）将无限期地挂起，因为队列已被完全处理，但是消费者不会知道生产已经完成。 （非常感谢StackOverflow用户提供的一些帮助，帮助他们整理了main（）：关键是等待q.join（），该操作将阻塞直到队列中的所有项目都已被接收并处理，然后取消使用方）任务，否则将挂断并无休止地等待其他队列项目出现。） 这是完整的脚本： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#!/usr/bin/env python3# asyncq.pyimport asyncioimport itertools as itimport osimport randomimport timeasync def makeitem(size: int = 5) -&gt; str: return os.urandom(size).hex()async def randsleep(a: int = 1, b: int = 5, caller=None) -&gt; None: i = random.randint(0, 10) if caller: print(f\"{caller} sleeping for {i} seconds.\") await asyncio.sleep(i)async def produce(name: int, q: asyncio.Queue) -&gt; None: n = random.randint(0, 10) for _ in it.repeat(None, n): # Synchronous loop for each single producer await randsleep(caller=f\"Producer {name}\") i = await makeitem() t = time.perf_counter() await q.put((i, t)) print(f\"Producer {name} added &lt;{i}&gt; to queue.\")async def consume(name: int, q: asyncio.Queue) -&gt; None: while True: await randsleep(caller=f\"Consumer {name}\") i, t = await q.get() now = time.perf_counter() print(f\"Consumer {name} got element &lt;{i}&gt;\" f\" in {now-t:0.5f} seconds.\") q.task_done()async def main(nprod: int, ncon: int): q = asyncio.Queue() producers = [asyncio.create_task(produce(n, q)) for n in range(nprod)] consumers = [asyncio.create_task(consume(n, q)) for n in range(ncon)] await asyncio.gather(*producers) await q.join() # Implicitly awaits consumers, too for c in consumers: c.cancel()if __name__ == \"__main__\": import argparse random.seed(444) parser = argparse.ArgumentParser() parser.add_argument(\"-p\", \"--nprod\", type=int, default=5) parser.add_argument(\"-c\", \"--ncon\", type=int, default=10) ns = parser.parse_args() start = time.perf_counter() asyncio.run(main(**ns.__dict__)) elapsed = time.perf_counter() - start print(f\"Program completed in {elapsed:0.5f} seconds.\") 前几个协程是辅助函数，它们返回一个随机字符串，一个小数秒性能计数器和一个随机整数。 生产者将1到5个项目放入队列中。 每个项目都是（i，t）的元组，其中i是随机字符串，t是生产者尝试将元组放入队列的时间。 消费者将商品拉出时，它仅使用放入商品的时间戳来计算该商品在队列中的经过时间。 请记住，asyncio.sleep（）用于模仿其他一些更复杂的协程，如果这是常规的阻止函数，则会消耗时间并阻止所有其他执行。 这是由两个生产者和五个消费者进行的测试： 1234567891011121314151617181920212223$ python3 asyncq.py -p 2 -c 5Producer 0 sleeping for 3 seconds.Producer 1 sleeping for 3 seconds.Consumer 0 sleeping for 4 seconds.Consumer 1 sleeping for 3 seconds.Consumer 2 sleeping for 3 seconds.Consumer 3 sleeping for 5 seconds.Consumer 4 sleeping for 4 seconds.Producer 0 added &lt;377b1e8f82&gt; to queue.Producer 0 sleeping for 5 seconds.Producer 1 added &lt;413b8802f8&gt; to queue.Consumer 1 got element &lt;377b1e8f82&gt; in 0.00013 seconds.Consumer 1 sleeping for 3 seconds.Consumer 2 got element &lt;413b8802f8&gt; in 0.00009 seconds.Consumer 2 sleeping for 4 seconds.Producer 0 added &lt;06c055b3ab&gt; to queue.Producer 0 sleeping for 1 seconds.Consumer 0 got element &lt;06c055b3ab&gt; in 0.00021 seconds.Consumer 0 sleeping for 4 seconds.Producer 0 added &lt;17a8613276&gt; to queue.Consumer 4 got element &lt;17a8613276&gt; in 0.00022 seconds.Consumer 4 sleeping for 5 seconds.Program completed in 9.00954 seconds. 在这种情况下，项目将在几分之一秒内完成处理。延迟可能有两个原因： 标准，在很大程度上是不可避免的开销当项目出现在队列中时所有消费者都在睡觉的情况 关于第二个原因，幸运的是，扩展到成百上千的消费者是完全正常的。 python3 asyncq.py -p 5 -c 100应该没有问题。这里的要点是，从理论上讲，您可以在不同的系统上使用不同的用户来控制生产者和消费者的管理，而队列则作为中心吞吐量。 到目前为止，您已经陷入困境，并看到了三个相关的示例，这些示例显示了异步调用用async和await定义的协程。如果您不完全遵循或只是想更深入地了解现代协程在Python中的使用机理，那么您将从第一节开始下一节。 异步IO的根源之前，您看到了一个基于生成器的老式协程的示例，这些协程已被更明确的本地协程过时了。该示例值得稍作调整以重新显示： 12345678910111213141516import asyncio@asyncio.coroutinedef py34_coro(): \"\"\"Generator-based coroutine\"\"\" # No need to build these yourself, but be aware of what they are s = yield from stuff() return sasync def py35_coro(): \"\"\"Native coroutine, modern syntax\"\"\" s = await stuff() return sasync def stuff(): return 0x10, 0x20, 0x30 作为实验，如果不经等待就调用py34_coro（）或py35_coro（），而没有等待，也没有对asyncio.run（）或其他asyncio“瓷器”函数的任何调用，会发生什么？ 孤立地调用协程将返回协程对象： 12&gt;&gt;&gt; py35_coro()&lt;coroutine object py35_coro at 0x10126dcc8&gt; 表面上这不是很有趣。 单独调用协程的结果是一个等待的协程对象。 测验时间：Python还有什么其他功能？ （当单独调用Python时，Python的什么功能实际上并没有“做什么”？） 希望您将生成器视为此问题的答案，因为协程是引擎盖下的增强型生成器。 在这方面，行为是相似的： 12345678&gt;&gt;&gt; def gen():... yield 0x10, 0x20, 0x30...&gt;&gt;&gt; g = gen()&gt;&gt;&gt; g # Nothing much happens - need to iterate with `.__next__()`&lt;generator object gen at 0x1012705e8&gt;&gt;&gt;&gt; next(g)(16, 32, 48) 碰巧的是，生成器函数是异步IO的基础（无论您是否使用异步def声明协程，而不是使用旧的@ asyncio.coroutine包装器声明协程）。 从技术上讲，等待比从收益更类似于收益。 （但请记住，x（）的收益只是句法糖，可以代替x（）中的i：收益i。） 与异步IO有关的生成器的一项关键功能是可以有效地随意停止和重新启动它们。 例如，您可以中断对生成器对象的迭代，然后在以后的其余值上恢复迭代。 当生成器函数达到yield时，它会生成该值，但随后会处于空闲状态，直到被告知要生成其后续值。 可以通过一个示例充实一下： 1234567891011121314151617181920&gt;&gt;&gt; from itertools import cycle&gt;&gt;&gt; def endless():... \"\"\"Yields 9, 8, 7, 6, 9, 8, 7, 6, ... forever\"\"\"... yield from cycle((9, 8, 7, 6))&gt;&gt;&gt; e = endless()&gt;&gt;&gt; total = 0&gt;&gt;&gt; for i in e:... if total &lt; 30:... print(i, end=\" \")... total += i... else:... print()... # Pause execution. We can resume later.... break9 8 7 6 9 8 7 6 9 8 7 6 9 8&gt;&gt;&gt; # Resume&gt;&gt;&gt; next(e), next(e), next(e)(6, 9, 8) 关键字await的行为类似，它标记了协程自身暂停并让其他协程工作的断点。在这种情况下，“暂停”是指已暂时放弃控制权但尚未完全退出或结束的协程。请记住，收益率，从广义上讲是等待收益率，是生成器执行过程中的一个断点。 这是函数和生成器之间的根本区别。一个功能是全有还是全无。一旦启动，它不会停止，直到它返回收益，然后将该值推送给调用方（调用它的函数）。另一方面，发电机每次达到产量时都会暂停，并且不再前进。它不仅可以将该值推送到调用堆栈，而且还可以在通过调用next（）恢复它时保留其局部变量。 发电机的第二个鲜为人知的功能也很重要。您也可以通过其.send（）方法将值发送到生成器中。这允许生成器（和协程）相互调用（等待）而不会阻塞。我不会再赘述此功能了，因为它主要对幕后协程的实现很重要，但是您根本不需要自己直接使用它。 如果您有兴趣探索更多内容，可以从正式引入协程的PEP 342开始。布雷特·坎农（Brett Cannon）的《如何在Python中进行异步等待》也是一本不错的书，关于异步的PYMOTW文章也很不错。最后，还有大卫·比兹利（David Beazley）的有关协程和并发的好奇课程，它深入探讨了协程的运行机制。 让我们尝试将以上所有文章压缩成几句话：这些协程实际上是通过一种特殊的非常规机制运行的。它们的结果是异常对象的属性，该异常对象在调用其.send（）方法时被抛出。所有这些还有更多的细节，但这可能无法帮助您在实践中使用这部分语言，因此，让我们继续。 为了将事情联系在一起，以下是协程作为生成器的一些关键点： 协程是经过重新利用的生成器，可以利用生成器方法的独特性。 基于老式生成器的协程使用yield from等待协程结果。本机协程中的现代Python语法仅将yield from与await替换为等待协程结果的方法。等待类似于从中获得收益，通常有助于将其视为收益。 使用await是标记断点的信号。它允许协程暂时中止执行，并允许程序稍后返回。 其他功能：异步和异步生成器+理解与普通的async / await一起，Python还使async用于在异步迭代器上进行迭代。异步迭代器的目的是使它能够在迭代时在每个阶段调用异步代码。 这个概念的自然扩展是异步生成器。回想一下，您可以在本地协程中使用wait，return或yield。在Python 3.6中（通过PEP 525）可以在协程中使用yield，它引入了异步生成器，目的是允许在同一个协程函数体中使用wait和yield： 1234567&gt;&gt;&gt; async def mygen(u: int = 10):... \"\"\"Yield powers of 2.\"\"\"... i = 0... while i &lt; u:... yield 2 ** i... i += 1... await asyncio.sleep(0.1) 最后但并非最不重要的一点是，Python使用async for启用了异步理解。 像它的堂兄一样，这主要是句法糖 123456789101112&gt;&gt;&gt; async def main():... # This does *not* introduce concurrent execution... # It is meant to show syntax only... g = [i async for i in mygen()]... f = [j async for j in mygen() if not (j // 3 % 5)]... return g, f...&gt;&gt;&gt; g, f = asyncio.run(main())&gt;&gt;&gt; g[1, 2, 4, 8, 16, 32, 64, 128, 256, 512]&gt;&gt;&gt; f[1, 2, 16, 32, 256, 512] 这是一个关键的区别：异步生成器和理解都不会使迭代并发。他们所做的只是提供同步对象的外观，但具有使所讨论的循环放弃对事件循环的控制权以便其他协程运行的能力。 换句话说，异步迭代器和异步生成器并未设计为在序列或迭代器上同时映射某些功能。它们只是为了让封闭的协程允许其他任务轮流使用。仅在使用plain for或with会“破坏”协程中await的性质的情况下，才需要async for和async with语句。异步和并发之间的区别是要把握的关键。 事件循环和asyncio.run（）您可以将事件循环想像为while True循环，它监视协程，获取有关空闲状态的反馈并四处寻找可以同时执行的事情。当协程正在等待的东西可用时，它能够唤醒一个空闲的协程。 到目前为止，事件循环的整个管理已由一个函数调用隐式处理： 1asyncio.run(main()) # Python 3.7+ Python 3.7中引入的asyncio.run（）负责获取事件循环，运行任务直到将其标记为完成，然后关闭事件循环。 使用get_event_loop（），可以更广泛地管理asyncio事件循环。 典型的模式如下所示： 12345loop = asyncio.get_event_loop()try: loop.run_until_complete(main())finally: loop.close() 在较早的示例中，您可能会看到loop.get_event_loop（）随处可见，但是除非您特别需要微调对事件循环管理的控制，否则asyncio.run（）对于大多数程序而言就足够了。 如果确实需要与Python程序中的事件循环进行交互，则循环是一种老式的Python对象，它支持使用loop.is_running（）和loop.is_closed（）进行内省。 如果您需要获得更精细的控制，则可以进行操作，例如在通过将循环作为参数传递来计划回调的过程中。 更关键的是要对事件循环的机制有一些了解。 以下是有关事件循环的一些要点。 ＃1：协同程序只有在与事件循环相关联的情况下，才能自行完成很多工作。 您之前在有关发电机的说明中已经看到了这一点，但值得重申。 如果您有一个等待他人的主要协程，则简单地单独调用它几乎没有效果： 12345678910&gt;&gt;&gt; import asyncio&gt;&gt;&gt; async def main():... print(\"Hello ...\")... await asyncio.sleep(1)... print(\"World!\")&gt;&gt;&gt; routine = main()&gt;&gt;&gt; routine&lt;coroutine object main at 0x1027a6150&gt; 请记住使用asyncio.run（）通过调度main（）协程（未来对象）在事件循环上执行来实际强制执行： 123&gt;&gt;&gt; asyncio.run(routine)Hello ...World! （其他协程可以使用await执行。通常只将main（）包装在asyncio.run（）中，然后从那里调用带有await的链式协程。） ＃2：默认情况下，异步IO事件循环在单个线程和单个CPU内核上运行。通常，在一个CPU内核中运行一个单线程事件循环绰绰有余。也可以跨多个内核运行事件循环。请查看约翰·里斯（John Reese）的演讲，以获取更多信息，并被警告您的笔记本电脑可能会自燃。 ＃3。事件循环是可插入的。也就是说，如果您确实需要，可以编写自己的事件循环实现，并使它运行相同的任务。这在uvloop软件包中得到了很好的演示，该软件包是Cython中事件循环的实现。 这就是术语“可插入事件循环”的含义：您可以使用事件循环的任何可行实现，而与协程本身的结构无关。 asyncio程序包本身带有两种不同的事件循环实现，默认实现基于选择器模块。 （第二种实现仅适用于Windows。） 完整程序：异步请求到目前为止，您已经做到了，现在该是有趣而轻松的部分了。在本部分中，您将使用aiohttp（一个非常快的异步HTTP客户端/服务器框架）构建一个抓取网址的网址收集器areq.py。 （我们只需要客户端部分。）这样的工具可用于映射站点集群之间的连接，链接形成有向图。 注意：您可能想知道为什么Python的请求包与异步IO不兼容。请求建立在urllib3的顶部，而urllib3则使用Python的http和套接字模块。 默认情况下，套接字操作处于阻塞状态。这意味着Python不会喜欢await request.get（url），因为.get（）无法等待。相反，aiohttp中的几乎所有内容都是可等待的协程，例如session.request（）和response.text（）。否则，它是一个很棒的软件包，但是您通过使用异步代码中的请求来对自己造成损害。 高级程序结构如下所示： 从本地文件urls.txt中读取URL序列。 发送对URL的GET请求并解码结果内容。如果失败，请在此处停止输入URL。 在响应的HTML中的href标记内搜索URL。 将结果写到foundurls.txt。 尽可能异步和同时执行上述所有操作。 （将aiohttp用于请求，将aiofiles用于文件附件。这是两个非常适合异步IO模型的IO主要示例。） 这是urls.txt的内容。它并不庞大，并且包含流量最高的网站： 123456789$ cat urls.txthttps://regex101.com/https://docs.python.org/3/this-url-will-404.htmlhttps://www.nytimes.com/guides/https://www.mediamatters.org/https://1.1.1.1/https://www.politico.com/tipsheets/morning-moneyhttps://www.bloomberg.com/markets/economicshttps://www.ietf.org/rfc/rfc2616.txt 列表中的第二个URL应该返回404响应，您需要对其进行适当处理。 如果您正在运行此程序的扩展版本，则可能需要处理比这更棘手的问题，例如服务器断开连接和无止尽的重定向。 请求本身应该使用单个会话发出，以充分利用会话的内部连接池。 让我们看一下完整的程序。 我们将逐步介绍以下内容： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108#!/usr/bin/env python3# areq.py\"\"\"Asynchronously get links embedded in multiple pages' HMTL.\"\"\"import asyncioimport loggingimport reimport sysfrom typing import IOimport urllib.errorimport urllib.parseimport aiofilesimport aiohttpfrom aiohttp import ClientSessionlogging.basicConfig( format=\"%(asctime)s %(levelname)s:%(name)s: %(message)s\", level=logging.DEBUG, datefmt=\"%H:%M:%S\", stream=sys.stderr,)logger = logging.getLogger(\"areq\")logging.getLogger(\"chardet.charsetprober\").disabled = TrueHREF_RE = re.compile(r'href=\"(.*?)\"')async def fetch_html(url: str, session: ClientSession, **kwargs) -&gt; str: \"\"\"GET request wrapper to fetch page HTML. kwargs are passed to `session.request()`. \"\"\" resp = await session.request(method=\"GET\", url=url, **kwargs) resp.raise_for_status() logger.info(\"Got response [%s] for URL: %s\", resp.status, url) html = await resp.text() return htmlasync def parse(url: str, session: ClientSession, **kwargs) -&gt; set: \"\"\"Find HREFs in the HTML of `url`.\"\"\" found = set() try: html = await fetch_html(url=url, session=session, **kwargs) except ( aiohttp.ClientError, aiohttp.http_exceptions.HttpProcessingError, ) as e: logger.error( \"aiohttp exception for %s [%s]: %s\", url, getattr(e, \"status\", None), getattr(e, \"message\", None), ) return found except Exception as e: logger.exception( \"Non-aiohttp exception occured: %s\", getattr(e, \"__dict__\", {}) ) return found else: for link in HREF_RE.findall(html): try: abslink = urllib.parse.urljoin(url, link) except (urllib.error.URLError, ValueError): logger.exception(\"Error parsing URL: %s\", link) pass else: found.add(abslink) logger.info(\"Found %d links for %s\", len(found), url) return foundasync def write_one(file: IO, url: str, **kwargs) -&gt; None: \"\"\"Write the found HREFs from `url` to `file`.\"\"\" res = await parse(url=url, **kwargs) if not res: return None async with aiofiles.open(file, \"a\") as f: for p in res: await f.write(f\"{url}\\t{p}\\n\") logger.info(\"Wrote results for source URL: %s\", url)async def bulk_crawl_and_write(file: IO, urls: set, **kwargs) -&gt; None: \"\"\"Crawl &amp; write concurrently to `file` for multiple `urls`.\"\"\" async with ClientSession() as session: tasks = [] for url in urls: tasks.append( write_one(file=file, url=url, session=session, **kwargs) ) await asyncio.gather(*tasks)if __name__ == \"__main__\": import pathlib import sys assert sys.version_info &gt;= (3, 7), \"Script requires Python 3.7+.\" here = pathlib.Path(__file__).parent with open(here.joinpath(\"urls.txt\")) as infile: urls = set(map(str.strip, infile)) outpath = here.joinpath(\"foundurls.txt\") with open(outpath, \"w\") as outfile: outfile.write(\"source_url\\tparsed_url\\n\") asyncio.run(bulk_crawl_and_write(file=outpath, urls=urls)) 该脚本比我们最初的玩具程序要长，所以让我们对其进行分解。 常量HREF_RE是一个正则表达式，用于提取我们最终在HTML中搜索的href标签： 12&gt;&gt;&gt; HREF_RE.search('Go to &lt;a href=\"https://realpython.com/\"&gt;Real Python&lt;/a&gt;')&lt;re.Match object; span=(15, 45), match='href=\"https://realpython.com/\"'&gt; 协程fetch_html（）是GET请求的包装，用于发出请求并解码生成的页面HTML。 它发出请求，等待响应，并在非200状态下立即引发： 12resp = await session.request(method=\"GET\", url=url, **kwargs)resp.raise_for_status() 如果状态正常，则fetch_html（）返回页面HTML（str）。 值得注意的是，此功能没有完成任何异常处理。 逻辑是将该异常传播给调用者，并在那里进行处理： 1html = await resp.text() 我们正在等待session.request（）和resp.text（），因为它们是等待的协程。否则，请求/响应周期将是应用程序的长尾，耗时的部分，但是对于异步IO，fetch_html（）可使事件循环在其他易于使用的作业（例如，解析和写入已获取的URL）上工作。 协同程序链中的下一个是parse（），它在fetch_html（）中等待给定的URL，然后从该页面的HTML中提取所有href标记，确保每个标记均有效并将其格式化为绝对路径。 诚然，parse（）的第二部分是阻塞的，但是它由快速的正则表达式匹配组成，并确保将发现的链接设置为绝对路径。 在这种特定情况下，此同步代码应该快速而不起眼。但是，请记住，给定协程中的任何行都会阻塞其他协程，除非该行使用yield，await或return。如果解析是一个比较繁琐的过程，则可能需要考虑使用loop.run_in_executor（）在其自己的过程中运行此部分。 接下来，协程write（）接收一个文件对象和一个URL，然后等待parse（）返回一组已解析的URL，通过使用aiofiles（用于打包的包）将每个URL及其源URL异步写入文件中。异步文件IO。 最后，bulk_crawl_and_write（）是脚本协程链的主要入口。它使用单个会话，并为最终从urls.txt中读取的每个URL创建一个任务。 以下是一些值得一提的其他要点： 默认的ClientSession具有最多100个打开连接的适配器。要更改此设置，请将asyncio.connector.TCPConnector的实例传递给ClientSession。您还可以基于每个主机指定限制。 您可以为整个会话和单个请求指定最大超时。 该脚本还使用async with，它与异步上下文管理器一起使用。我没有专门讨论这个概念，因为从同步上下文管理器到异步上下文管理器的过渡非常简单。后者必须定义.__ aenter （）和. aexit （）而不是. exit （）和. enter __（）。如您所料，async with只能在用async def声明的协程函数中使用。 如果您想了解更多内容，请在GitHub上的本教程随附文件中还附带注释和文档字符串。 这是所有执行情况的结果，因为areq.py在一秒钟之内即可获取，解析并保存9个网址的结果： 1234567891011121314151617181920212223$ python3 areq.py21:33:22 DEBUG:asyncio: Using selector: KqueueSelector21:33:22 INFO:areq: Got response [200] for URL: https://www.mediamatters.org/21:33:22 INFO:areq: Found 115 links for https://www.mediamatters.org/21:33:22 INFO:areq: Got response [200] for URL: https://www.nytimes.com/guides/21:33:22 INFO:areq: Got response [200] for URL: https://www.politico.com/tipsheets/morning-money21:33:22 INFO:areq: Got response [200] for URL: https://www.ietf.org/rfc/rfc2616.txt21:33:22 ERROR:areq: aiohttp exception for https://docs.python.org/3/this-url-will-404.html [404]: Not Found21:33:22 INFO:areq: Found 120 links for https://www.nytimes.com/guides/21:33:22 INFO:areq: Found 143 links for https://www.politico.com/tipsheets/morning-money21:33:22 INFO:areq: Wrote results for source URL: https://www.mediamatters.org/21:33:22 INFO:areq: Found 0 links for https://www.ietf.org/rfc/rfc2616.txt21:33:22 INFO:areq: Got response [200] for URL: https://1.1.1.1/21:33:22 INFO:areq: Wrote results for source URL: https://www.nytimes.com/guides/21:33:22 INFO:areq: Wrote results for source URL: https://www.politico.com/tipsheets/morning-money21:33:22 INFO:areq: Got response [200] for URL: https://www.bloomberg.com/markets/economics21:33:22 INFO:areq: Found 3 links for https://www.bloomberg.com/markets/economics21:33:22 INFO:areq: Wrote results for source URL: https://www.bloomberg.com/markets/economics21:33:23 INFO:areq: Found 36 links for https://1.1.1.1/21:33:23 INFO:areq: Got response [200] for URL: https://regex101.com/21:33:23 INFO:areq: Found 23 links for https://regex101.com/21:33:23 INFO:areq: Wrote results for source URL: https://regex101.com/21:33:23 INFO:areq: Wrote results for source URL: https://1.1.1.1/ 不太破旧！ 作为健全性检查，您可以检查输出中的行数。 以我为例，是626，但请注意，这可能会有所波动： 1234567$ wc -l foundurls.txt 626 foundurls.txt$ head -n 3 foundurls.txtsource_url parsed_urlhttps://www.bloomberg.com/markets/economics https://www.bloomberg.com/feedbackhttps://www.bloomberg.com/markets/economics https://www.bloomberg.com/notices/tos 后续步骤：如果您想提高底注，请使此网络爬虫递归。 您可以使用aio-redis跟踪树中已爬网的URL以避免两次请求，并将链接与Python的networkx库连接。 记住要友善。 发送1000个并发请求到一个小的，毫无戒心的网站是不好的，不好的，不好的。 有一些方法可以限制您在一批中发出的并发请求，例如使用asyncio的sempahore对象或使用类似这种模式的方法。 如果您不注意此警告，则可能会收到大量TimeoutError异常，最终只会损害您自己的程序。 上下文中的异步IO既然您已经看了很多健康的代码，那么让我们退一步，考虑一下什么时候异步IO是理想的选择，以及如何进行比较以得出结论或选择其他并发模型。 什么时候以及为什么异步IO是正确的选择？本教程不适用于异步IO，线程与多处理的扩展论述。但是，了解异步IO何时可能是三个中的最佳候选者很有用。 异步IO与多处理之间的斗争根本不是一场争斗。实际上，它们可以一起使用。如果您有多个相当统一的CPU约束任务（一个很好的例子是在诸如scikit-learn或keras之类的库中进行网格搜索），那么多处理应该是一个明显的选择。 如果所有函数都使用阻塞调用，则简单地在每个函数之前放置异步是一个坏主意。 （这实际上可能会使您的代码变慢。）但是，如前所述，异步IO和多处理在某些地方可以和谐共处。 异步IO与线程之间的竞争更为直接。我在导言中提到“线程很难实现”。全文是，即使在线程似乎易于实现的情况下，由于竞争条件和内存使用等原因，它仍可能导致臭名昭著的无法跟踪的错误。 由于线程是具有有限可用性的系统资源，因此线程的扩展也往往比异步IO的扩展规模小。在许多计算机上创建数千个线程将失败，因此我不建议您首先尝试。创建数千个异步IO任务是完全可行的。 当您有多个IO绑定任务时，异步IO会发光，否则这些任务将通过阻塞IO绑定等待时间来控制，例如： 网络IO，无论您的程序是服务器端还是客户端 无服务器设计，例如对等，多用户网络（如群组聊天室） 您想要模仿“即弃即忘”风格的读/写操作，而不必担心在阅读和写入内容时锁定任何东西 不使用它的最大原因是，await仅支持定义一组特定方法的一组特定对象。如果您要对某个DBMS执行异步读取操作，则不仅需要查找该DBMS的Python包装器，还需要查找支持async / await语法的包装器。包含同步调用的协程会阻止其他协程和任务运行。 有关使用async / await的库的简短列表，请参阅本教程末尾的列表。 异步IO是，但是哪个？本教程重点介绍异步IO，异步/等待语法以及如何将异步用于事件循环管理和指定任务。当然，asyncio并不是唯一的异步IO库。纳撒尼尔·史密斯（Nathaniel J.Smith）的观察表明： 在几年内，asyncio可能会沦落为成为精明的开发人员避免使用的stdlib库之一，例如urllib2。 … 实际上，我要说的是asyncio是其自身成功的受害者：设计时，它使用了可能的最佳方法；但是从那时起，异步的启发下的工作（例如添加异步/等待）就改变了格局，以便我们可以做得更好，现在异步已被其早期的承诺所束缚。 （资源） 为此，尽管使用不同的API和不同的方法，但一些可以做asyncio的大牌替代品是curio和trio。我个人认为，如果您要构建大小适中，简单明了的程序，仅使用asyncio就足够了并且可以理解，并且可以避免在Python标准库之外添加其他大型依赖项。 但是，无论如何，请查看curio和trio，您可能会发现它们以相同的方式完成了对您来说对用户而言更直观的事情。这里介绍的许多与软件包无关的概念也应渗透到其他异步IO软件包中。 其他在接下来的几节中，您将介绍asyncio和async / await的其他各个部分，这些部分到目前为止还没有很好地适合本教程，但是对于构建和理解完整的程序仍然很重要。 其他顶级异步功能除了asyncio.run（）之外，您还看到了其他一些包级功能，例如asyncio.create_task（）和asyncio.gather（）。 您可以使用create_task（）安排协程对象的执行，然后使用asyncio.run（）： 123456789101112131415161718&gt;&gt;&gt; import asyncio&gt;&gt;&gt; async def coro(seq) -&gt; list:... \"\"\"'IO' wait time is proportional to the max element.\"\"\"... await asyncio.sleep(max(seq))... return list(reversed(seq))...&gt;&gt;&gt; async def main():... # This is a bit redundant in the case of one task... # We could use `await coro([3, 2, 1])` on its own... t = asyncio.create_task(coro([3, 2, 1])) # Python 3.7+... await t... print(f't: type {type(t)}')... print(f't done: {t.done()}')...&gt;&gt;&gt; t = asyncio.run(main())t: type &lt;class '_asyncio.Task'&gt;t done: True 这种模式有一个精妙之处：如果您不等待main（）中的内容，它可能会在main（）本身表示已完成之前就结束了。因为asyncio.run（main（））调用loop.run_until_complete（main（）），所以事件循环仅关注main（）完成（而不等待），而不涉及在main（）中创建的任务是否完成。完成。如果不等待，循环的其他任务可能会在完成之前被取消。如果需要获取当前待处理任务的列表，则可以使用asyncio.Task.all_tasks（）。 注意：asyncio.create_task（）是Python 3.7中引入的。在Python 3.6或更低版本中，请使用asyncio.ensure_future（）代替create_task（）。 另外，还有asyncio.gather（）。尽管它没有做任何特别的事情，但是collect（）的目的是将协程（期货）的集合整齐地放入单个未来中。结果，它返回一个未来的对象，并且，如果您等待asyncio.gather（）并指定多个任务或协程，则您正在等待所有这些任务或协程完成。 （这与我们前面的示例有点类似queue.join（）。）collect（）的结果将是输入结果的列表： 12345678910111213141516&gt;&gt;&gt; import time&gt;&gt;&gt; async def main():... t = asyncio.create_task(coro([3, 2, 1]))... t2 = asyncio.create_task(coro([10, 5, 0])) # Python 3.7+... print('Start:', time.strftime('%X'))... a = await asyncio.gather(t, t2)... print('End:', time.strftime('%X')) # Should be 10 seconds... print(f'Both tasks done: {all((t.done(), t2.done()))}')... return a...&gt;&gt;&gt; a = asyncio.run(main())Start: 16:20:11End: 16:20:21Both tasks done: True&gt;&gt;&gt; a[[1, 2, 3], [0, 5, 10]] 您可能已经注意到，collect（）等待传递给它的Future或协程的整个结果集。 或者，您可以遍历asyncio.as_completed（）以按完成顺序获取任务完成时的任务。 该函数返回一个迭代器，该迭代器在完成任务时产生任务。 下面，coro（[3，2，1]）的结果将在coro（[10，5，0]）完成之前可用，而collect（）则不是这样： 12345678910111213141516&gt;&gt;&gt; async def main():... t = asyncio.create_task(coro([3, 2, 1]))... t2 = asyncio.create_task(coro([10, 5, 0]))... print('Start:', time.strftime('%X'))... for res in asyncio.as_completed((t, t2)):... compl = await res... print(f'res: {compl} completed at {time.strftime(\"%X\")}')... print('End:', time.strftime('%X'))... print(f'Both tasks done: {all((t.done(), t2.done()))}')...&gt;&gt;&gt; a = asyncio.run(main())Start: 09:49:07res: [1, 2, 3] completed at 09:49:10res: [0, 5, 10] completed at 09:49:17End: 09:49:17Both tasks done: True 最后，您可能还会看到asyncio.ensure_future（）。 您几乎不需要它，因为它是一个较低级的管道API，并在很大程度上被稍后介绍的create_task（）所取代。 等待的先例尽管它们的行为有些相似，但是await关键字的优先级远高于yield。 这意味着，由于绑定更紧密，因此在许多情况下，您需要在yield from语句中使用括号，而在类似的await语句中则不需要。 有关更多信息，请参见PEP 492中的await表达式示例。 总结现在，您已经可以使用async / await和由此建立的库。 以下是您所涵盖内容的回顾： 异步IO作为与语言无关的模型，以及通过使协程彼此间接通信来实现并发的方法 Python新的async和await关键字的细节，用于标记和定义协程 asyncio，Python包，提供用于运行和管理协程的API","link":"/python/Python-AsyncIO-%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97/"},{"title":"数据库基础知识","text":"数据库基本知识基本概念数据库术语 数据库（database）：保存有组织的数据的容器。 数据表（table）：某种特定类型数据的结构化清单。 模式（schema）：数据库对象的集合，这个集合包含了各种对象如：表、视图、存储过程、索引等。 列（column）：表中的一个字段，一个数据表由一个或者多个列组成。 行（row）：数据表中的一行数据记录。 主键（primary key）：一列或者一组列，其值能否唯一标识数据表中的一行。 SQL语法 SQL 指结构化查询语言 SQL 使我们有能力访问数据库 SQL 是一种 ANSI 的标准计算机语言 SQL语法结构包 字句：是语句和查询的组成成分。 表达式：可以产生任何标量值，或由列和行的数据库表。 谓词：给需要评估的SQL三值逻辑（3VL）（true/false/unknown）或布尔真值指定条件，并限制语句和查询效果，或改变程序流程。 查询：基于特定的条件检索数据。 语句：可以持久地影响纲要和数据，也可以控制数据库事务，程序流程，连接，会话或诊断。 SQL语法要点 SQL语句不区分大小写，但是数据库表名，列名和值是否区分，依赖于具体的DBMS以及配置。 多条SQL语句必须以分好（；）分隔。 处理SQL语句时，所有空格都被忽略；SQL语句可以写成一行，也可以分写为多行。 1234567-- 一行 SQL 语句UPDATE user SET username='biyeyi', password='biyeyi' WHERE username = 'root';-- 多行 SQL 语句UPDATE userSET username='biyeyi', password='biyeyi'WHERE username = 'root'; SQL支持三种注释 123## 注释1-- 注释2/* 注释3 */ SQL分类数据定义语言（DDL）数据定义语言（Data Definition Language，DDL）是 SQL 语言集中负责数据结构定义与数据库对象定义的语言。 DDL 的主要功能是定义数据库对象。 DDL 的核心指令是 CREATE、ALTER、DROP。 数据操纵语言（DML）数据操纵语言（Data Manipulation Language, DML）是用于数据库操作，对数据库其中的对象和数据运行访问工作的编程语句。 DML 的主要功能是 访问数据，因此其语法都是以读写数据库为主。 DML 的核心指令是 INSERT、UPDATE、DELETE、SELECT。这四个指令合称 CRUD（Create, Read, Update, Delete），即增删改查。 事务控制语言（TCL）事务控制语言 (Transaction Control Language, TCL) 用于管理数据库中的事务。这些用于管理由 DML 语句所做的更改。它还允许将语句分组为逻辑事务。 TCL 的核心指令是 COMMIT、ROLLBACK。 数据控制语言（DCL）数据控制语言 (Data Control Language, DCL) 是一种可对数据访问权进行控制的指令，它可以控制特定用户账户对数据表、查看表、预存程序、用户自定义函数等数据库对象的控制权。 DCL 的核心指令是 GRANT、REVOKE。 DCL 以控制用户的访问权限为主，因此其指令作法并不复杂，可利用 DCL 控制的权限有：CONNECT、SELECT、INSERT、UPDATE、DELETE、EXECUTE、USAGE、REFERENCES。 根据不同的 DBMS 以及不同的安全性实体，其支持的权限控制也有所不同。 （以下为 DML 语句用法） 增删改查 增删改查，又称为 CRUD，数据库基本操作中的基本操作。 插入数据插入完整的行 12-- INSERT INTO 语句用于向表中插入新记录。INSERT INTO user VALUES (10, 'root', 'root', 'xxxx@163.com'); 插入行的一部分 1INSERT INTO user(username, password, email) VALUES ('admin', 'admin', 'xxxx@163.com'); 插入查询出来的数据 1INSERT INTO user(username) SELECT name FROM account; 更新数据12-- UPDATE 语句用于更新表中的记录。UPDATE userSET username='biyeyi', password='biyeyi' WHERE username = 'root'; 删除数据 DELETE 语句用于删除表中的记录。 TRUNCATE TABLE 可以清空表，也就是删除所有行。 删除表中的指定数据 1DELETE FROM user WHERE username = 'biyeyi'; 清空表中的数据 1TRUNCATE TABLE user; 查询数据 SELECT 语句用于从数据库中查询数据。 DISTINCT 用于返回唯一不同的值。它作用于所有列，也就是说所有列的值都相同才算相同。 LIMIT 限制返回的行数。可以有两个参数，第一个参数为起始行，从 0 开始；第二个参数为返回的总行数。 查询单列 1SELECT prod_name FROM products; 查询多列 1SELECT prod_id, prod_name, prod_price FROM products; 查询所有列 1SELECT * FROM products; 查询不同的值 1SELECT DISTINCT vend_id FROM products; 限制查询结果 12345-- 返回前 5 行SELECT * FROM mytable LIMIT 5;SELECT * FROM mytable LIMIT 0, 5;-- 返回第 3 ~ 5 行SELECT * FROM mytable LIMIT 2, 3;","link":"/front-end/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"title":"全网新闻全知道之利用 Python AsyncIO 抓取百度新闻","text":"网络上关于Python的异步相关的文章已经很多了，但是成体系地完整抓取的教程还是比较少的，正好最近做了百度新闻的爬虫，正好借此机会实践了 Python 的 AsyncIO，利用异步进行爬虫的编写，提高爬取速度。 本文所有代码基于 Python 3.8 编写，低版本可能在API上有所区别，在此请注意。 什么是异步 Async所谓异步，是相对于同步来说的。正常情况下，程序是一行一行运行的，如果一行代码运行耗时很久，就会一直卡在当前位置。这样的行为对于计算密集型程序（如计算数据）是没有问题的，毕竟CPU一直在运算。但是对于IO密集型程序（如爬虫），大量时间被消耗在等待缓慢的IO设备上（如网络请求、数据库操作等），CPU在等待期间什么事也没做，浪费了算力。这样当然是不可以接受的。 在过去，Python语言中实现IO高并发，通常是通过多线程或者多进程来实现的，但是由于相关编程的难度和容易出错等问题，导致并不能快速地编写出可用的程序。 用过JavaScript语言的同学肯定知道，JS也是单线程的，但是JS通过回调、Promise、async/await等实现了异步操作，运行IO密集型程序的效率很高。 在Python最近的几个版本中，实现了一种称为AsyncIO的库，和JS一样使用了 async/await 关键字来标明异步操作，将异步代码的写法向同步代码靠近，便于理解。 Python语言如何实现 IO 高并发？Python 实现异步的方法和 JS 类似，都采用了一种称为事件循环(event loop)的模型，将任务放进这个模型中，会自动在CPU可用时执行任务，并在任务完成时进行回调，然后继续执行下一个任务，CPU就可用一直处于工作状态，而不是经常性地等待IO的返回结果。 在 Python 中，我们可以把async关键字加在函数的def关键字之前，声明一个异步函数，也称之为协程（coroutine），可以理解为&quot;可以放进事件循环的任务&quot;。 构建百度新闻爬虫程序的基本框架以下是本文编写的程序的基本框架 123456789101112131415161718192021222324252627282930#!/usr/bin/env python3# -*- coding: UTF-8 -*-import asyncioimport aiohttpimport uvloop# 设置uvloop，提高运行速度asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())class BaiduNewsCrawler: def __init__(self): pass async def loop_crawl(self): print('start') await asyncio.sleep(3) print('end') def run(self): try: # 启动异步程序 asyncio.run(self.loop_crawl()) except KeyboardInterrupt: print('stopped by yourself!')if __name__ == '__main__': c = BaiduNewsCrawler() c.run() 程序主要功能介绍创建数据库本程序基于公司名称，搜索该公司的相关新闻并进行爬取，就此设计了数据库，代码如下 本文设计了两个表，一个是company表，存储公司的信息和状态，另外一个是news表，保存跟公司相关的新闻的信息，两个表通过company_id进行关联。 1234567891011121314151617181920212223242526@staticmethoddef create_db(): db = sqlite3.connect('stock.db') cursor = db.cursor() cursor.execute( \"CREATE TABLE IF NOT EXISTS company (id INTEGER PRIMARY KEY AUTOINCREMENT, name VARCHAR(50), code VARCHAR(20), current_pn INTEGER, status INTEGER);\") cursor.execute( \"\"\" CREATE TABLE IF NOT EXISTS news ( id INTEGER PRIMARY KEY AUTOINCREMENT, company_id INTEGER, title VARCHAR(500), posttime VARCHAR(50), news_ts INTEGER, subsitename VARCHAR(50), url VARCHAR(600) unique, baidu_json TEXT, html_lzma BLOB, status INTEGER, created_ts INTEGER, CONSTRAINT fk_company FOREIGN KEY (company_id) REFERENCES company(id) ); \"\"\") db.commit() return db, cursor 百度新闻爬虫逻辑查询数据库，遍历公司名称123456789101112131415161718async def loop_crawl(self): self.session = aiohttp.ClientSession() while True: # 这里的 _workers_max 控制了同时请求的数量 self.cursor.execute('select * from company where status=1 limit ?', (self._workers_max,)) company_records = self.cursor.fetchall() if not len(company_records): break task_list = [] for rec in company_records: self.logger.info(f'crawl {rec[1]} pn: {rec[3]}') # 生成任务列表 task = asyncio.create_task(self.crawl(rec)) task_list.append(task) # 运行当前的任务列表 await asyncio.wait(task_list) await self.session.close() 具体分析网络请求我们都知道，在Chrome浏览器里打开开发者工具的网络板块，可以看到请求的情况，我们可以在需要模拟的请求上点击右键，然后选择Copy，再选择Copy as cURL，这时候请求的详情会被复制为一条curl命令。 点此打开 Convert cURL 在此介绍一个非常好用的工具。这个工具的功能就是把curl命令转换为程序代码，比如Python的代码，这样子就不用我们自己一行行地把请求里面的信息抄到代码里了。 当然，这个工具生成的python代码是基于requests库的，我们需要进行一点微小的修改，使其适合aiohttp库使用。 自定义请求函数这里为了进行请求重试，作者加入了tenacity库，可以通过装饰器@retry引入重试功能。 同时为了每次请求的UA都不同，这里自定义了一个随机UA的小工具。 12345678910111213141516@retry(stop=stop_after_attempt(2), wait=wait_random(min=2, max=5))async def fetch(session, url, params, headers, cookies, timeout=9, to_json=False, random_ua=True): if random_ua or 'User-Agent' not in headers: headers['User-Agent'] = RandomUserAgent().random async with session.get(url, params=params, cookies=cookies, headers=headers, timeout=timeout) as response: status = response.status if to_json: html = await response.json() else: html = await response.read() encoding = response.get_encoding() if encoding == 'gb2312': encoding = 'gbk' html = html.decode(encoding, errors='ignore') redirected_url = str(response.url) return status, html, redirected_url 爬取函数1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950async def crawl(self, company_record): # 将全局的访问参数进行浅拷贝 p = params.copy() company_id = company_record[0] # 修改为当前的参数 p['word'] = company_record[1] current_pn = company_record[3] p['pn'] = str(current_pn) try: # 尝试请求 status, json_resp, redirected_url = await su.fetch( self.session, 'https://m.baidu.com/sf/vsearch', params=p, headers=headers, cookies=cookies, to_json=True ) except RetryError as ex: # 对于请求异常过多的情况，写入数据库进行记录 self.cursor.execute('update company set status=0 where id = ?;', (company_id,)) self.db.commit() return else: # 请求正常获取数据 if status == 200 and json_resp['errno'] == 0: news_list = json_resp['data']['list'] for item in news_list: try: # 把当前页的新闻依次插入数据库 self.cursor.execute(\"\"\" insert into news (company_id, title, posttime, subsitename, url, baidu_json, status, created_ts, news_ts) values (?, ?, ?, ?, ?, ?, ?, ?, ?) \"\"\", ( company_id, item['title'], item['posttime'], item['subsitename'], item['url'], json.dumps(item), 1, su.get_unix_timestamp(), su.convert_baidu_news_datetime_to_unix_ts(item['posttime']), )) except: # 对于网址有重复的情况，由于数据库已经对url字段做了unique限制，所以插入重复的url会导致报错，这里直接跳过即可 print(item['url'], 'duplicate') continue if not json_resp['data']['hasMore']: # 当前公司的相关新闻已经爬取完毕，直接标记公司的状态为2，结束爬取 self.cursor.execute('update company set status=2 where id = ?;', (company_id,)) else: # 翻页 self.cursor.execute('update company set current_pn=? where id = ?;', (current_pn + 10, company_id)) self.db.commit() 构建具体新闻页的爬虫上文介绍了爬取百度新闻的代码。这部分我们来了解如何大规模爬取具体的新闻页。 由于百度上得到的新闻页来自很多外部新闻网站，因此并不适用于上文的顺序爬取的方法。 为了尽最大可能降低对网站的压力（也是为了防止被网址屏蔽），在此采用了URL池的做法（参考了猿人学的代码，但是进行了一些改动）将不同网站的URL分别存储，每次请求的时候尽可能访问不同的网站，避免集中访问同一个网站。 首先将所有数据库里面的URL放入池中，在此没有考虑性能和内存，一股脑读了进来。 123456789101112def push_to_pool(self, news): host = urlparse(news.url).netloc if not host or '.' not in host: print('try to push_to_pool with bad url:', news.url, ', len of ur:', len(news.url)) return False if host in self.waiting: if news in self.waiting[host]: return True self.waiting[host].add(news) else: self.waiting[host] = {news} return True 然后开始死循环，不断提取URL 12345678910111213141516def pop(self, size): result = [] waiting_len = len(self.waiting) sample_len = min(waiting_len, size) hosts = random.sample(list(self.waiting), k=sample_len) for host in hosts: result.append(self.pop_by_host(host)) counter = size - waiting_len while counter &gt; 0 and len(self.waiting): host = random.choice(list(self.waiting)) result.append(self.pop_by_host(host)) counter -= 1 return result 访问URL 1234567async def crawl(self, news): status, html, redirected_url = await su.fetch_without_retry( self.session, news.url, headers=headers, ) self.set_status(news, status, html) 根据请求的结果写入数据库 123456789101112131415161718192021def set_status(self, news, status_code, html): if news in self.pending: self.pending.pop(news) if status_code == 200: # 正常情况，把html压缩后存入数据库 html_lzma = lzma.compress(html) self.cursor.execute('update news set status=2, html_lzma=? where id = ?;', (html_lzma, news.id,)) elif status_code == 404: self.cursor.execute('update news set status=0 where id = ?;', (news.id,)) elif news in self.failure: self.failure[news] += 1 if self.failure[news] &gt; self.failure_threshold: self.cursor.execute('update news set status=0 where id = ?;', (news.id,)) self.failure.pop(news) else: self.add(news) else: self.failure[news] = 1 self.add(news) self.db.commit() 本文首发于毕业pro官网","link":"/python/%E5%85%A8%E7%BD%91%E6%96%B0%E9%97%BB%E5%85%A8%E7%9F%A5%E9%81%93%E4%B9%8B%E5%88%A9%E7%94%A8Python-AsyncIO%E6%8A%93%E5%8F%96%E7%99%BE%E5%BA%A6%E6%96%B0%E9%97%BB/"},{"title":"全网开发小工具集合","text":"Unicode转换 ASCII对照表 BASE64图片编解码 BASE64文本编解码 Unix时间戳转换 墨刀 原型设计工具 Markdown表格生成工具 RegExr 正则表达式测试工具 IP查询接口 https://api.ip.sb/geoip 加解密工具 ProcessOn Ubuntu pastebin Ubuntu在线剪贴板 httpstatus HTTP状态码测试 httpbin HTTP Curl转换成代码 BootCDN 国内的CDN加速服务 JsLint 在线检查JS语法 Can I Use 检查JS、CSS、HTML等浏览器兼容性 jsPerf 分析JS代码性能 sojson JSON格式化 TinyPng 大幅度压缩图片尺寸","link":"/other/%E5%85%A8%E7%BD%91%E5%BC%80%E5%8F%91%E5%B0%8F%E5%B7%A5%E5%85%B7%E9%9B%86%E5%90%88/"},{"title":"Python 学习资源一把梭（长期更新）","text":"本文首发于博客 网络上的 Python 学习资源如此之多，我们面对的最大的问题不是没有学习资料，而是如何找到最好的并且最适合自己的学习资料。 搭建基础Python环境传送门 廖雪峰老师 Python 教程目前网络上最简单全面的 Python 入门教程之一，涵盖了新手需要知道的大部分知识。新手只需要从开头看到错误处理部分即可。 传送门 常见开发工具 PyCharm JetBrain公司开发的IDE，目前Python语言最好用的集成开发工具，盲选！功能强大，具有大量的智能识别功能，便于新手发现代码的问题 JupyterLab 著名的iPython的继承者，在网页上写python代码，同时直接显示结果，便于反复尝试不同的思路，同时最后可以生成漂亮的PDF或者网页，便于发布查看。 爬虫相关库 requests 优雅的 HTTP 请求库，容易上手，便于与其他代码集成使用，新手可以1分钟只能写出一个可用的爬虫程序 scrapy 经典的Python爬虫框架，封装了大量完善的爬虫逻辑，将大部分繁琐的爬虫编写工作进行了简化，强烈推荐学习 aiohttp 基于AsyncIO的异步HTTP请求库，最低要求 Python 3.5.3，使用户不再需要了解线程和进程的知识，即可利用异步API实现并行操作，在IO密集型程序上体现出极大的性能优势 selenium 用于控制浏览器进行网页访问的库，常用于反爬虫的情况 网站开发 flask 简单易学的Web开发框架，上手快，但是也具有很好的扩展性，具有很多第三方插件 django 集成大量功能的开发框架，需要学习入门教程熟悉，上手之后会非常有效率 sanic 异步Web框架，需要python 3.6以上版本，满足高并发要求 机器学习 pandas 著名的数据处理和分析库，利用DataFrame快速批量处理数据 scikit-learn 经典机器学习库，集成了分类、回归、聚类、降维、NLP等算法 numpy 科学计算的基础库，具有强力的N维数组 matplotlib 最强可视化库，画图就靠这个了 seaborn 基于matplotlib的可视化库，可以方便地画漂亮的图 自然语言处理 jieba 最强大的中文分词工具 hanlp 面向生产环境的多语种自然语言处理工具包 gensim 话题模型库","link":"/python/Python-%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%BA%90%E4%B8%80%E6%8A%8A%E6%A2%AD%EF%BC%88%E9%95%BF%E6%9C%9F%E6%9B%B4%E6%96%B0%EF%BC%89/"},{"title":"Python matplotlib 直方图填充斜线 方便论文打印","text":"1234567891011121314151617import pandas as pdimport matplotlib.pyplot as pltplt.rcParams['savefig.dpi'] = 300name_list = ['RSA','DES','3DES','AES']num_list = [21,17,14,12]# 配置填充的图形patterns = ('/','//','-','\\\\')fig = plt.figure(figsize=(8,6), dpi=72, facecolor=\"white\")axes = plt.subplot(111)for i,pattern in enumerate(patterns): axes.bar( name_list[i], num_list[i], hatch=pattern, color='white',edgecolor='black',)# 设置X轴上的文字axes.set_xticks(name_list)plt.savefig('abc.png')plt.show()","link":"/python/Python-matplotlib-%E7%9B%B4%E6%96%B9%E5%9B%BE%E5%A1%AB%E5%85%85%E6%96%9C%E7%BA%BF-%E6%96%B9%E4%BE%BF%E8%AE%BA%E6%96%87%E6%89%93%E5%8D%B0/"},{"title":"纯纯小白向 Windows下如何配置Python开发环境","text":"Python 版本介绍目前来说，Python主要分为2.7和3+两个版本，部分老版本的程序可能需要Python 2.7运行，但是现在新的库一般都是支持3的。本答案只介绍3有关的环境配置。 如果你是这样的： Windows 下的 Python 3+ 的用户 我什么都不知道 那只看这一篇就够啦～let’s go!面向纯纯小白的最简单不走弯路啥也不知道反正跟着快乐就完事了方案就在这里！ Python 程序下载 点击进入下载页面: Windows 版本下载地址 滚动到下载页面最下面，选择圈出的文件进行下载 安装过程 打开下载回来的文件，开始安装，记得选上Add Python 3.8 to PATH，这样才能在cmd命令提示符运行Python程序哦！切记！ 点击Install Now，就可以安安静静等待安装完成啦！ 康康有没有安装成功？ 点击左下角到开始菜单，一般来说会显示最新安装的Python程序，但是这还不够，我们需要验证命令提示符下是否安装成功 在开始菜单输入cmd，看到如图所示的命令提示符之后，按回车打开 打开之后，会出现下面这样的窗口，不用害怕这个黑乎乎的东西！输入python -V康康有没有反应！如果安装成功的话，这里会提示Python X.X.X这样的信息，如果不是则说明安装失败 验证pip是否已经安装，输入pip -V，如果提示了类似下面的信息，则说明安装成功！ 到此为止，最最最基本的环境已经安装完成啦～撒花～🎉 安装基本的开发工具虽然说这些没有安装也不影响用Python，但是，这些真的是特别特别特别方便小白的！想当年如果我知道这些东西该少走多少弯路！为了不让其他小白也被折磨，我在这里都给大家说！ 安装pipenv虚拟环境管理器pipenv是一个用于管理虚拟环境的集成工具，过去我们用pip安装包的时候，都是安装到全局，这样子的话不方便管理，特别是碰到不同的程序需要不同的版本的包的时候，就会引起冲突，因此有了pipenv，可以让我们针对每个Python程序都有一个独立的环境，总之就是，简单！干净！强推！ 接着在上面打开的cmd窗口输入命令python -m pip install pipenv，有的朋友可能安装比较慢，也可以在这条命令最后加上-i https://mirrors.aliyun.com/pypi/simple，这样的话就可以使用阿里提供的国内加速服务来安装啦！ 运行之后静静等待安装完成～ 安装PyCharm开发工具PyCharm是由一家名为JetBrains的捷克软件开发公司制作的，是一款特别好用、智能的集成开发环境（IDE），非常非常适合小白使用，利于规避初学者可能犯的很多错误！不要跟我说什么自带的编辑器就够用了，小白碰到错误的时候都不知道哪里错了好吗？！有简单好用的工具为什么不用？ 打开下载页面，一般选择这个免费的Community版本就可以了 打开下载回来的安装文件，一路回车安装就可以 开始创建新项目 打开刚刚安装的PyCharm，选择Create New Project创建新项目 填写项目基本信息，完成后点击下面的Create按钮 PyCharm开始创建项目，稍等即可 打开后，可以看到项目的根目录创建了一个Pipfile文件，这个文件很重要，里面记录了这个项目使用的Python的版本和需要用的库，不能删除！ 创建一个Python文件试试看 右键点击项目名称，如图所示，创建一个Python文件 输入文件名，按回车，然后打开该文件 输入代码 1print('知乎 爱写程序的小哥哥') （可选，强烈建议）修改代码文件的换行符为LF - Unix and macOS (\\n)，这样在和使用Linux和Mac的同学交换文件的时候，具有更好的兼容性，否则可能造成一些报错提示哦 右键点击编辑区域，在快捷菜单里点击Run ‘run’，即可运行当前Python程序了！是不是很激动！ 安装库的方法 打开PyCharm内置的命令提示符，它会自动切换到当前的项目目录，很方便 假设我们需要安装requests库，则输入pipenv install requests 安装完成之后，可以康康Pipfile文件，可以发现多了一行，也就是刚刚安装的库 （可选）安装 JupyterLabJupyterLab的鼎鼎大名很多朋友都知道，在此演示如何安装 首先在PyCharm的命令提示符内运行pipenv install jupyterlab安装本体 运行pipenv install ipykernel安装内核管理工具（为了保证JupyterLab可以引用当前虚拟环境所安装的包） 运行python -m ipykernel install --user --name=my-virtualenv-name创建内核 运行jupyter lab启动 JupyterLab","link":"/python/%E7%BA%AF%E7%BA%AF%E5%B0%8F%E7%99%BD%E5%90%91-Windows%E4%B8%8B%E5%A6%82%E4%BD%95%E9%85%8D%E7%BD%AEPython%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/"},{"title":"[ 7 ] 手把手搭建基于 Nuxt.js SSR 的网站 如何编写 Express 后端 API","text":"经过前面教程的学习，我们已经搭建了基本的页面，现在我们来了解如何编写后端的 API。打开 server/index.js 文件，可以看到这是一个 Express 程序，加载了 Nuxt.js 的中间件，实现了服务端渲染。我们需要添加自己的路由文件，实现 API。这里建议 API 的路径前缀设置为 api，便于区分前后端路由。 新建接口在 server 文件夹下建立 routes 文件夹，并新建 post.js 文件。 123server└── routes └── post.js post.js 文件的内容如下，这里写了一个简单的接口作为示范 1234567891011121314const express = require('express')const router = express.Router()router.get('/list', (req, res) =&gt; { res.json({ result: [ { title: 'a' }, { title: 'b' }, { title: 'c' } ] })})module.exports = router; 修改 server/index.js 文件 123456789101112131415161718192021222324252627282930313233343536373839const express = require('express')const consola = require('consola')const { Nuxt, Builder } = require('nuxt')const app = express()// Import and Set Nuxt.js optionsconst config = require('../nuxt.config.js')config.dev = process.env.NODE_ENV !== 'production'/******* 引用路由文件 *******/const postRouter = require('./routes/post')async function start () { // Init Nuxt.js const nuxt = new Nuxt(config) const { host, port } = nuxt.options.server await nuxt.ready() // Build only in dev mode if (config.dev) { const builder = new Builder(nuxt) await builder.build() } /******* 加载自定义路由 *******/ app.use('/api/post', postRouter) // Give nuxt middleware to express app.use(nuxt.render) // Listen the server app.listen(port, host) consola.ready({ message: `Server listening on http://${host}:${port}`, badge: true })}start() 修改完成了，可以访问 http://localhost:3000/api/post/list 查看结果，可以看到接口返回的 JSON 数据已经展示在浏览器里了。 现在将接口数据引入前端页面，打开 pages/index.vue 文件，修改如下内容，完成了尝试打开首页，发现已经被正确渲染到页面了。 12345678async asyncData ({ $http }) { // 修改 url 为本地的 API const url = 'http://localhost:3000/api/post/list' const response = await $http.$get(url) return { postList: response.result }} 慢着，这里的请求地址似乎不太对结束了吗？显然这里是有问题的。作为一个既可能在服务端运行也可能在客户端运行的方法，asyncData 方法直接访问 localhost 是不合适的，假设在客户端运行的话，去哪里找这个 localhost 呢，用户并不会在本地运行一个服务端。 修改 pages/index.vue 文件 12345678910export default { async asyncData ({ $http }) { // 注意这里的相对路径不能以 / 开头 const url = 'api/post/list' const response = await $http.$get(url) return { postList: response.result } }} 修改 pages/about.vue 文件 123456789&lt;template&gt; &lt;div&gt; about &lt;!-- 增加链接 --&gt; &lt;nuxt-link to=\"/\"&gt; 回首页 &lt;/nuxt-link&gt; &lt;/div&gt;&lt;/template&gt; 从局域网访问可以用其他设备访问页面，但是由于之前没有设置服务器地址，所以要修改 nuxt.config.js 文件，增加 server 属性，之后可以从任意局域网内的设备对本地 IP 进行访问了。 1234server: { port: 3000, // default: 3000 host: '0.0.0.0' // default: localhost} 验证异步请求修改完成后，通过其他设备访问 http://localhost:3000，可以看到首页渲染正常。 我们跳转到 about 页，再点击”回首页”，可以发现请求失败。通过观察开发者工具的 Network -&gt; XHR，可以发现浏览器的异步请求访问了 localhost 开头的 URL，这肯定是错误的。 这时候我们需要在 nuxt.config.js 文件中增加如下配置。 123http: { browserBaseURL: '/'} 修改完成后，刷新 http://localhost:3000/about，通过点击”回首页”来返回首页，可以在开发者工具的 XHR 里面看到执行了首页的异步请求。","link":"/front-end/nuxtjs%E6%95%99%E7%A8%8B/7-%E6%89%8B%E6%8A%8A%E6%89%8B%E6%90%AD%E5%BB%BA%E5%9F%BA%E4%BA%8E-Nuxt-js-SSR-%E7%9A%84%E7%BD%91%E7%AB%99-%E5%A6%82%E4%BD%95%E7%BC%96%E5%86%99-Express-%E5%90%8E%E7%AB%AF-API/"},{"title":"[ 6 ] 手把手搭建基于 Nuxt.js SSR 的网站 如何加载 UI 库","text":"为了更好地演示如何加载 UI 样式库，本文选择了 buefy 进行说明。buefy 是一种基于 bulma 的 Vue 组件库，外观整洁且轻量，便于自己定制样式。 安装 buefy 首先安装包 1yarn add buefy 编写加载组件的插件代码创建 buefy.js 文件 12plugins├── buefy.js 修改 buefy.js 文件代码，引入所有组件 1234567import Vue from 'vue'import Buefy from 'buefy'// 对于不需要覆盖官方默认样式的情况，这样引入CSS就可以了import 'buefy/dist/buefy.css'// 引入所有组件Vue.use(Buefy) 修改 nuxt.config.js，对 buefy 进行加载 123plugins: [ { src: '~/plugins/buefy.js' }] 修改首页 index.vue 代码在顶层的 div 上增加了 container 样式，内部增加了 box 样式。完成后刷新页面看下结果，可以观察到页面内容增加了一个外边框。 12345678910111213141516171819&lt;template&gt; &lt;!-- 修改这里 --&gt; &lt;div class=\"container\"&gt; &lt;div class=\"box\"&gt; &lt;h1&gt;首页&lt;/h1&gt; &lt;nuxt-link to=\"/about\"&gt; About &lt;/nuxt-link&gt; &lt;div&gt; &lt;div v-for=\"post in postList\" :key=\"post.id\" &gt; {{ post.title }} &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/template&gt; 按需引入组件 修改 buefy.js 文件代码 12345678910111213141516import Vue from 'vue'import 'buefy/dist/buefy.css'import { Loading, Toast, Dialog, Input, Navbar, Table, Carousel, Icon, Button, Tooltip, Tag, Pagination } from 'buefy'Vue.use(Loading)Vue.use(Toast)Vue.use(Dialog)Vue.use(Input)Vue.use(Navbar)Vue.use(Table)Vue.use(Carousel)Vue.use(Icon)Vue.use(Button)Vue.use(Tooltip)Vue.use(Tag)Vue.use(Pagination) 修改首页 index.vue 代码，增加一个 buefy 的按钮组件 1234567891011121314151617181920&lt;template&gt; &lt;div class=\"container\"&gt; &lt;div class=\"box\"&gt; &lt;h1&gt;首页&lt;/h1&gt; &lt;nuxt-link to=\"/about\"&gt; About &lt;/nuxt-link&gt; &lt;!-- 修改这里 --&gt; &lt;b-button&gt;测试按钮&lt;/b-button&gt; &lt;div&gt; &lt;div v-for=\"post in postList\" :key=\"post.id\" &gt; {{ post.title }} &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/template&gt;","link":"/front-end/nuxtjs%E6%95%99%E7%A8%8B/6-%E6%89%8B%E6%8A%8A%E6%89%8B%E6%90%AD%E5%BB%BA%E5%9F%BA%E4%BA%8E-Nuxt-js-SSR-%E7%9A%84%E7%BD%91%E7%AB%99-%E5%A6%82%E4%BD%95%E5%8A%A0%E8%BD%BD-UI-%E5%BA%93/"},{"title":"[ 5 ] 手把手搭建基于 Nuxt.js SSR 的网站 如何创建前端路由","text":"前文已经实现了简单的 SSR 网站，本节将介绍如何实现前端路由。 最基本的路由在 pages 文件夹下创建 about.vue 文件 12345678910111213&lt;template&gt; &lt;div&gt; about &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default {}&lt;/script&gt;&lt;style&gt;&lt;/style&gt; 修改 pages/index.vue 文件的模版 12345678910111213141516&lt;template&gt; &lt;div&gt; &lt;h1&gt;首页&lt;/h1&gt; &lt;nuxt-link to=\"/about\"&gt; About &lt;/nuxt-link&gt; &lt;div&gt; &lt;div v-for=\"post in postList\" :key=\"post.id\" &gt; {{ post.title }} &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/template&gt; 这里采用了 nuxt-link 标签包裹链接，nuxt-link 是 vue-router 的包装，基本是一样的。重新刷新网页，可以看到 About 上具有链接，点击即可跳转到新的网页 http://localhost:3000/about。 动态路由动态路径在 pages 文件夹下建立 _dynamicname 文件夹，文件夹结构如下所示 1234./pages├── _dynamicname│ ├── index.vue│ └── other.vue _dynamicname 文件夹下的 index.vue 文件内容为 12345&lt;template&gt; &lt;div&gt; 动态路由首页 &lt;/div&gt;&lt;/template&gt; _dynamicname 文件夹下的 other.vue 文件内容为 1234567891011121314&lt;template&gt; &lt;div&gt; 动态路由 其他页 &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default { asyncData (ctx) { // eslint-disable-next-line no-console console.log(ctx.route.params.dynamicname) }}&lt;/script&gt; 在 Nuxt.js 中，pages 文件夹下的路径与前端路由直接相关。其中带有下划线 _ 开头的文件夹或者文件都表示是一个变量，表现在地址上就是这一块是允许变化的。 上面的文件创建完成后，我们可以分别访问 http://localhost:3000/test 和 http://localhost:3000/test/other 进行查看，注意到其中的 test 即为路由变量 _dynamicname 的值。在访问 http://localhost:3000/test/other 的时候可以查看终端的打印结果，可以看到 test 的输出。 动态参数如何创建带有对象 ID 的路由呢？先创建 post 文件夹，同时在其中创建 _id.vue 文件 123./pages└── post └── _id.vue _id.vue 文件内容为 12345678910111213&lt;template&gt; &lt;div&gt; post: {{ id }} &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default { asyncData ({ params }) { return { id: params.id } }}&lt;/script&gt; 访问 http://localhost:3000/post/3，可以看到页面输出 post: 3。URL 中的3即映射到了 params 参数的 id 属性。 嵌套路由上面的动态参数路由，在通常情况下，可以满足我们对于实现对象实例页面的需要，但是当我们需要对子路由包裹一层父级界面的话，我们需要做下面的操作创建 users.vue 文件和 users 文件夹，包括里面的 _id.vue 文件和 index.vue 文件 12345./pages├── users│ ├── _id.vue│ └── index.vue└── users.vue users.vue 文件内容为 123456&lt;template&gt; &lt;div&gt; &lt;h1&gt;PARENT&lt;/h1&gt; &lt;nuxt-child /&gt; &lt;/div&gt;&lt;/template&gt; _id.vue 文件内容为 12345678910111213&lt;template&gt; &lt;div&gt; user id: {{ id }} &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default { asyncData ({ params }) { return { id: params.id } }}&lt;/script&gt; index.vue 文件内容为 12345&lt;template&gt; &lt;div&gt; users 首页 &lt;/div&gt;&lt;/template&gt; 访问 http://localhost:3000/users 页面，我们可以看到页面最上方有一个 PARENT，作为父级 UI，会包裹下面的所有子路由。里层则是上述的 index.vue 文件内容。访问 http://localhost:3000/users/2 页面，则发现里层内容变成了 user id: 2。 动态嵌套路由上面的例子可能还不够复杂，下面来演示动态嵌套路由的做法，构建如 http://localhost:3000/{路由变量}/{路由变量}/{变量} 的路由。首先创建如下所示结构的文件 1234567./pages├── _dynamicnested│ ├── _subCategory│ │ ├── _id.vue│ │ └── index.vue│ └── _subCategory.vue├── _dynamicnested.vue _dynamicnested.vue 文件内容如下，dynamicnested 被自动映射到 route.params 下的属性 1234567891011121314&lt;template&gt; &lt;div&gt; &lt;h1&gt;_dynamicnested param: {{ dynamicNestedName }}&lt;/h1&gt; &lt;nuxt-child/&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default { asyncData ({ route }) { return { dynamicNestedName: route.params.dynamicnested } }}&lt;/script&gt; _subCategory.vue 文件内容为，同样，这里的 subCategory 也被映射到了 route.params 的属性 1234567891011121314&lt;template&gt; &lt;div&gt; &lt;h1&gt;_subCategory.vue param: {{ subDynamicName }}&lt;/h1&gt; &lt;nuxt-child /&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default { asyncData ({ route }) { return { subDynamicName: route.params.subCategory } }}&lt;/script&gt; index.vue 文件内容为 12345&lt;template&gt; &lt;div&gt; &lt;h3&gt;首页&lt;/h3&gt; &lt;/div&gt;&lt;/template&gt; _id.vue 文件内容如下，这里的 id 因为不属于路由的内容，所以被映射到 params 的属性 12345678910111213&lt;template&gt; &lt;div&gt; _id {{ id }} &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default { asyncData ({ params }) { return { id: params.id } }}&lt;/script&gt; 访问 http://localhost:3000/dynamicparent/subdynamic 可以看到如下所示，可以看到，URL 中的 dynamicparent 成为了 dynamicnested 属性的值，而 subdynamic 成为了 subCategory 属性的值 访问 http://localhost:3000/dynamicparent/subdynamic/3 结果如下 参考官方路由文档","link":"/front-end/nuxtjs%E6%95%99%E7%A8%8B/5-%E6%89%8B%E6%8A%8A%E6%89%8B%E6%90%AD%E5%BB%BA%E5%9F%BA%E4%BA%8E-Nuxt-js-SSR-%E7%9A%84%E7%BD%91%E7%AB%99-%E5%A6%82%E4%BD%95%E5%88%9B%E5%BB%BA%E5%89%8D%E7%AB%AF%E8%B7%AF%E7%94%B1/"},{"title":"[ 4 ] 手把手搭建基于 Nuxt.js SSR 的网站 创建自己的首页","text":"本节将详细描述如何编写前后端代码 安装 @nuxt/http 模块 首先进行安装，@nuxt/http 是官方网站所使用的请求模块，基于 ky 模块 1yarn add @nuxt/http 配置 nuxt.config.js 123modules: [ '@nuxt/http'] 编写代码把 pages/index.vue 的内容修改为如下代码，运行 yarn dev 查看结果 1234567891011121314151617&lt;template&gt; &lt;div&gt; &lt;h1&gt;首页&lt;/h1&gt; &lt;h2&gt;标题1&lt;/h2&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default { asyncData (context) { console.dir(context) }}&lt;/script&gt;&lt;style&gt;&lt;/style&gt; 可以注意到，以上代码包含了一个 Vue 中没有的方法 asyncData，这是 Nuxt 特有的方法，用来在服务端和客户端执行网络请求代码。 我们发现，这里的日志打印到了本地的终端里，而不是浏览器的 Console，这是因为当前页面在浏览器中输入网址打开后，这里的 asyncData 方法是在服务端执行的。 观察打印的结果，我们可以看到，这里的 context 包含了 isDev、error、env、req、res、route、params、query等属性，在编写代码时会经常用到。 下面我们来修改页面代码，访问网络上的公用 API 来测试一下。 123456789101112131415161718192021222324252627282930313233&lt;template&gt; &lt;div&gt; &lt;h1&gt;首页&lt;/h1&gt; &lt;h2&gt;标题1&lt;/h2&gt; &lt;div&gt; &lt;div v-for=\"post in postList\" :key=\"post.id\" &gt; {{ post.title }} &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default { async asyncData (context) { // async asyncData ({ $http }) { // $http 可以利用 ES6 的 Object Destructing，在参数里进行解包获取 const url = 'http://jsonplaceholder.typicode.com/posts' // const response = await $http.$get(url) const response = await context.$http.$get(url) return { // 这里的 postList 会被融合到 this.data 中 postList: response } }}&lt;/script&gt;&lt;style&gt;&lt;/style&gt; 结果如图所示，此时已经完成了最基本的 SSR 网站。","link":"/front-end/nuxtjs%E6%95%99%E7%A8%8B/4-%E6%89%8B%E6%8A%8A%E6%89%8B%E6%90%AD%E5%BB%BA%E5%9F%BA%E4%BA%8E-Nuxt-js-SSR-%E7%9A%84%E7%BD%91%E7%AB%99-%E5%88%9B%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E9%A6%96%E9%A1%B5/"},{"title":"如何缓解黑苹果出现色彩断层(color banding)问题","text":"我的配置：显卡为蓝宝石RX570 4G显示器是AOC U2790PQU 解决方案安装黑苹果之后，系统信息里显示器显示为30bit色彩，但是safari的毛玻璃效果下看桌面会有色彩断层现象，查询到色彩断层在英文里似乎表述为color banding，就此进行google。查到这样一个解决方案 下载SwitchResX 启动后在顶栏图标菜单下选择Millions of Colors，此时系统信息的显卡一栏里应该是Framebuffer Depth: 24-Bit Color (ARGB8888) 经过对显示器信息的查询，支持10bit色彩，不知道为什么在mac下不支持了，暂时没有解决这个疑惑。 参考：相关讨论 The steps are incredibly simple without any technical skill.Open HackintoolSwitch to the Tools tab and press Disable Gatekeeper and mount the disk in read/write mode (for macOS Catalina and later only)Switch to the Display tab and just export without changing anythingAs Hackintool has generated 3 files and 1 folder to Desktop, just drag the folder DisplayVendorID-xxxx to /System/Library/Displays/Contents/Resources/OverridesRestart","link":"/hardware/%E5%A6%82%E4%BD%95%E7%BC%93%E8%A7%A3%E9%BB%91%E8%8B%B9%E6%9E%9C%E5%87%BA%E7%8E%B0%E8%89%B2%E5%BD%A9%E6%96%AD%E5%B1%82-color-banding-%E9%97%AE%E9%A2%98/"},{"title":"[ 3 ] 手把手搭建基于 Nuxt.js SSR 的网站 认识Nuxt.js工程的目录结构和配置","text":"目录结构打开终端，cd 到工程根目录，运行 tree 命令查看目录结构 1tree -I \"node_modules\" 结果如下 123456789101112131415161718192021222324252627.├── README.md├── assets # 程序中需要参加编译的资源，比如SCSS，Less│ └── README.md├── components # Vue组件│ ├── Logo.vue│ └── README.md├── layouts # Nuxt.js 中用于全局布局的模版，一般不用管│ ├── README.md│ └── default.vue├── middleware # 中间件，用于在页面渲染前运行代码，可以判断在服务端还是客户端运行 https://nuxtjs.org/guide/routing/#middleware│ └── README.md├── nuxt.config.js # Nuxt.js 最最最重要的配置文件├── package.json├── pages # 工程的所有页面，基于该文件夹下的目录结构自动生成前端路由│ ├── README.md│ └── index.vue├── plugins # 插件，用于载入部分包│ └── README.md├── server # 服务端代码│ └── index.js├── static # 静态文件，该文件在网站运行过程中，可以在根目录下访问│ ├── README.md│ └── favicon.ico├── store # Vuex│ └── README.md└── yarn.lock nuxt.config.js 配置文件以下是默认的文件内容，下面在文件中注释了这些配置的作用 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455module.exports = { mode: 'universal', /* ** Headers of the page */ head: { // 可以在这里修改全站页面的 head 信息 title: process.env.npm_package_name || '', meta: [ { charset: 'utf-8' }, { name: 'viewport', content: 'width=device-width, initial-scale=1' }, { hid: 'description', name: 'description', content: process.env.npm_package_description || '' } ], link: [ { rel: 'icon', type: 'image/x-icon', href: '/favicon.ico' } ] }, /* ** Customize the progress-bar color */ loading: { color: '#fff' }, // 页面加载进度条的颜色设置 /* ** Global CSS */ css: [ // 可以用来加载CSS/SCSS文件 ], /* ** Plugins to load before mounting the App */ plugins: [ // 加载自定义插件 ], /* ** Nuxt.js dev-modules */ buildModules: [ // 开发时使用的模块 // Doc: https://github.com/nuxt-community/eslint-module '@nuxtjs/eslint-module' ], /* ** Nuxt.js modules */ modules: [ // 载入第三方模块 // Doc: https://github.com/nuxt-community/dotenv-module '@nuxtjs/dotenv' ], /* ** Build configuration */ build: { // 编译配置 /* ** You can extend webpack config here */ extend (config, ctx) { } }} 注意，修改 nuxt.config.js 文件之后，需要重启服务也就是 Ctrl + C 关闭服务之后重新启动 yarn dev 常见配置问题（以下均为 nuxt.config.js 文件的根节点） 如何全局引入外部 script 文件？ 12345head: { script: [ { src: 'https://example.com' } ]} 如何自定义链接的 Active 样式？ 123router: { linkActiveClass: 'is-active'} 如何自定义加载进度条的样式？ 12345loading: { color: '#123456', height: '5px', throttle: 0} 如何载入自定义 CSS/SCSS 样式文件？ 123css: [ '@/assets/css/custom.scss',] 如何定义样式 SCSS 文件的全局变量？ 安装 @nuxtjs/style-resources1yarn add @nuxtjs/style-resources 引入模块123modules: [ '@nuxtjs/style-resources'] 在工程的根目录下的 assets 文件夹创建 /css/variable.scss 文件 写入内容，如1$hover-color: #123456; 修改 nuxt.config.js 文件12345styleResources: { scss: [ '@/assets/css/variable.scss' ]} 此时在 Vue 文件的样式内即可直接引用这个变量 使用 nuxt/http进行异步请求，但是部署后发现前端请求(AsyncData)访问的主机是 localhost？ 修改 http 模块的配置，设置前端请求的基础 URL123http: { browserBaseURL: '/'} 如何修改编译的输出目录？ 1buildDir: 'nuxt-dist' // 默认是 .nuxt 如何定义 CDN 服务器的地址？ 将编译输出目录下的 /dist/client 文件夹上传 CDN，假设把client文件夹重命名为 _nuxt 修改配置文件123build: { publicPath: IS_PROD ? CDN_PREFIX + '/_nuxt/' : '/_nuxt/'}","link":"/front-end/nuxtjs%E6%95%99%E7%A8%8B/3-%E6%89%8B%E6%8A%8A%E6%89%8B%E6%90%AD%E5%BB%BA%E5%9F%BA%E4%BA%8E-Nuxt-js-SSR-%E7%9A%84%E7%BD%91%E7%AB%99-%E8%AE%A4%E8%AF%86Nuxt-js%E5%B7%A5%E7%A8%8B%E7%9A%84%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84%E5%92%8C%E9%85%8D%E7%BD%AE/"},{"title":"[ 2 ] 手把手搭建基于 Nuxt.js SSR 的网站 如何搭建 Nuxt.js 的开发环境","text":"代码 github 地址https://github.com/uniblackfire/nuxtjstourial 需要的工具 Yarn后续所有安装操作都基于 Yarn 进行，这是一种新的包管理工具。 开发工具 Visual Studio Code Webstrom 创建项目在终端执行下面的命令即可开始创建新项目 1yarn create nuxt-app &lt;项目名&gt; 终端会有如下提示 包管理器，选择 Yarn UI 框架，根据自己的喜好进行选择，碧野选择了 None（如果不选择也可以在后续添加，不带有 Vue 组件的纯UI框架可以通过引入外部网站托管的文件来实现加载，减少对本地网络资源的消耗同时提高加载速度） 服务端框架，选择了 Express，因为该框架比较成熟，社区关于它的经验也比较丰富 Nuxt.js 模块，只选择了 DotEnv，用于加载工程根目录下的 .env 环境配置文件 linting 工具选择了 EsLint 测试框架没有选择 渲染模式选择通用，进行 SSR 开发工具没有选择 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849create-nuxt-app v2.14.0✨ Generating Nuxt.js project in nuxtdemo? Project name nuxtdemo? Project description My superior Nuxt.js project? Author name bitzx? Choose the package manager (Use arrow keys)❯ Yarn Npm ? Choose UI framework (Use arrow keys)❯ None Ant Design Vue Bootstrap Vue Buefy Bulma Element Framevuerk iView Tachyons Tailwind CSS Vuesax Vuetify.js? Choose custom server framework None (Recommended) AdonisJs ❯ Express Fastify Feathers hapi Koa Micro ? Choose Nuxt.js modules ◯ Axios ◯ Progressive Web App (PWA) Support❯◉ DotEnv? Choose linting tools (Press &lt;space&gt; to select, &lt;a&gt; to toggle all, &lt;i&gt; to invert selection)❯◉ ESLint ◯ Prettier ◯ Lint staged files ◯ StyleLint? Choose test framework (Use arrow keys)❯ None Jest AVA ? Choose rendering mode (Use arrow keys)❯ Universal (SSR) Single Page App? Choose development tools (Press &lt;space&gt; to select, &lt;a&gt; to toggle all, &lt;i&gt; to invert selection)❯◯ jsconfig.json (Recommended for VS Code) ◯ Semantic Pull Requests 配置完成后，会对上面选择的包进行安装。 修改 package.json修改完成请执行 yarn 进行安装 1234567\"dependencies\": { \"@nuxt/http\": \"^0.3.9\", \"@nuxtjs/dotenv\": \"^1.4.0\", \"cross-env\": \"^5.2.0\", \"express\": \"^4.17.1\", \"nuxt\": \"^2.11.0\"} 测试运行执行以下命令运行新创建的工程 12cd &lt;项目名&gt;yarn dev 提交初始代码12git add .git commit -m 'init' 参考Nuxt.js官方网站源代码 1git clone git@github.com:nuxt/nuxtjs.org.git","link":"/front-end/nuxtjs%E6%95%99%E7%A8%8B/2-%E6%89%8B%E6%8A%8A%E6%89%8B%E6%90%AD%E5%BB%BA%E5%9F%BA%E4%BA%8E-Nuxt-js-SSR-%E7%9A%84%E7%BD%91%E7%AB%99-%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA-Nuxt-js-%E7%9A%84%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/"},{"title":"[ 1 ] 手把手搭建基于 Nuxt.js SSR 的网站 为什么需要 Nuxt.js","text":"单页应用为什么不利于SEO随着前端技术发展，越来越多的前端开发转向了单页应用，也就是 Vue、React 这些框架。但是这些框架有一个非常大的问题，就是内容是靠 JavaScript 渲染的，服务器在初始阶段发送到浏览器的 HTML 并不包含内容。这就导致一个问题，如果搜索引擎不支持执行 JS 代码的话，他在爬取这个页面的时候就看不到任何具体内容，进而影响搜索引擎的收录和网站排名。 Server Side Render 是什么直接翻译就是“服务端渲染”，把原先在浏览器端由 JS 完成的内容渲染工作放到服务端进行，这样在浏览器初次访问的时候就可以直接获取到渲染完成的 HTML 文件。有朋友要说，我们完全可以回到服务端语言直接渲染模版的工作方式，这当然是可以的，但是这样又重新把前后端的工作交叉在一起，不便于前后端分工和对现有前端工程技术的使用。 为什么选择 Nuxt.js从 Vue 的官网可以了解到，完全可以自己搭建一套基于 Vue 的 SSR 环境，但是由于有了 Nuxt.js 的出现，我们可以把这些流程大大简化。Nuxt.js 提供了一整套 SSR 需要的环境和配置，同时有良好的社区支持，我们只需要在它的框架下就可以轻松实现 SSR。 为什么要写这个教程因为个人需要搭建网站，选择了这个技术之后发现相关中文文档不够全面，且官网中文文档滞后于英文文档，碰到的问题也几乎都是自己摸索或者从英文网站得到答案。希望可以记录下自己遇到的问题，方便后来者。 在这里可以学到什么 搭建船新的基于 Nuxt.js 的网站 了解其中的各种坑和技巧 学习后续教程需要了解的知识 VueNuxt.js 基于 Vue 开发，点此查看 Vue 的官方教程","link":"/front-end/nuxtjs%E6%95%99%E7%A8%8B/1-%E6%89%8B%E6%8A%8A%E6%89%8B%E6%90%AD%E5%BB%BA%E5%9F%BA%E4%BA%8E-Nuxt-js-SSR-%E7%9A%84%E7%BD%91%E7%AB%99/"},{"title":"2019年12月黑苹果折腾笔记及经验分享","text":"我的配置 CPU: Intel i5 4590 主板: 华硕B85 Pro Gamer 显卡: 蓝宝石 RX570 4G 折腾方法 下载黑果小兵的10.15.2的镜像 balenaEthcer写入镜像到一个优盘 开机设置BIOS里为优盘启动 安装macos 进入macos系统后，打开clover configurator，打开左侧的Mount EFI，查看右侧的Efi Partitions，分别Mount Partition硬盘和启动优盘，然后分别Open Partition，把启动优盘里的所有文件拷贝进硬盘里，这就实现了硬盘启动 重启电脑，关闭BIOS里的串行设备！（解决了睡眠唤醒后黑屏的问题！！！） 设置启动顺序，为硬盘上的UEFI开头的启动项！ 打开clover configurator，挂载本地硬盘，打开EFI文件夹，右键点击config.plist，选择clover configurator打开，选择左侧的SMBIOS，选择右侧的“上下”箭头的图标，选择iMacPro1,1的机型（开启独立显卡的硬件加速） 参考 i5 4590+ASUS B85 Pro Gamer+RX570黑苹果10.14.3的EFI分享 黑苹果安装笔记","link":"/hardware/2019%E5%B9%B412%E6%9C%88%E9%BB%91%E8%8B%B9%E6%9E%9C%E6%8A%98%E8%85%BE%E7%AC%94%E8%AE%B0%E5%8F%8A%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB/"},{"title":"JS Date函数比较","text":"","link":"/front-end/JS-Date%E5%87%BD%E6%95%B0%E6%AF%94%E8%BE%83/"},{"title":"Vue基础","text":"由于 JavaScript 的限制，Vue 不能检测以下变动的数组： 当你利用索引直接设置一个项时，这样写不会触发更新： 1vm.items[indexOfItem] = newValue 正确的方法： 123456// Vue.setVue.set(vm.items, indexOfItem, newValue)// Array.prototype.splicevm.items.splice(indexOfItem, 1, newValue)// 你也可以使用 vm.$set 实例方法，该方法是全局方法 Vue.set 的一个别名：vm.$set(vm.items, indexOfItem, newValue) 当你修改数组的长度时，这样写不会触发更新： 1vm.items.length = newLength 正确的方法： 1vm.items.splice(newLength) 不推荐同时使用 v-if 和 v-for。当 v-if 与 v-for 一起使用时，v-for 具有比 v-if 更高的优先级。 在使用 v-for 时，尽量提供 key。2.2.0+ 的版本里，当在组件中使用 v-for 时，key 现在是必须的。 使用修饰符时，顺序很重要；相应的代码会以同样的顺序产生。因此，用 v-on:click.prevent.self 会阻止所有的点击，而 v-on:click.self.prevent 只会阻止对元素自身的点击。 选择框，如果 v-model 表达式的初始值未能匹配任何选项，&lt;select&gt; 元素将被渲染为“未选中”状态。在 iOS 中，这会使用户无法选择第一个选项。因为这样的情况下，iOS 不会触发 change 事件。因此，更推荐像上面这样提供一个值为空的禁用选项(&lt;option disabled value=&quot;&quot;&gt;请选择&lt;/option&gt;)。 如果要自动过滤用户输入的首尾空白字符，可以给 v-model 添加 trim 修饰符。 Vue 提供了一个 $listeners 属性，它是一个对象，里面包含了作用在这个组件上的所有监听器。有了这个 $listeners 属性，你就可以配合 v-on=&quot;$listeners&quot; 将所有的事件监听器指向这个组件的某个特定的子元素。 .sync 修饰符 插槽 在向具名插槽提供内容的时候，我们可以在一个 &lt;template&gt; 元素上使用 v-slot 指令，并以 v-slot 的参数的形式提供其名称 混入 mixin 同名钩子函数将混合为一个数组，因此都将被调用。另外，混入对象的钩子将在组件自身钩子之前调用。 值为对象的选项，例如 methods, components 和 directives，将被混合为同一个对象。两个对象键名冲突时，取组件对象的键值对。 $nextTick 为了在数据变化之后等待 Vue 完成更新 DOM ，可以在数据变化之后立即使用 Vue.nextTick(callback) 。这样回调函数在 DOM 更新完成后就会调用。 Vuex mapState 获取状态 mapGetters 将 store 中的 getter 映射到局部计算属性 更改 Vuex 的 store 中的状态的唯一方法是提交 mutation。 1store.commit('increment') mutation 必须是同步函数 mapMutations 辅助函数将组件中的 methods 映射为 store.commit 调用（需要在根节点注入 store） Action 类似于 mutation，不同在于： Action 提交的是 mutation，而不是直接变更状态。 Action 可以包含任意异步操作。1store.dispatch('increment') mapActions 辅助函数将组件的 methods 映射为 store.dispatch 调用（需要先在根节点注入 store） 当网站足够大时，一个状态树下，根的部分字段繁多，解决这个问题就要模块化 vuex 默认情况下，模块内部的 action、mutation 和 getter 是注册在全局命名空间的——这样使得多个模块能够对同一 mutation 或 action 作出响应。 如果希望你的模块具有更高的封装度和复用性，你可以通过添加 namespaced: true 的方式使其成为带命名空间的模块。当模块被注册后，它的所有 getter、action 及 mutation 都会自动根据模块注册的路径调整命名。 完整的闭环是 store.dispatch(‘action’) -&gt; action -&gt; commit -&gt; mutation -&gt; getter -&gt; computed 建议是不论多简单的流程都跑完整个闭环，形成代码的统一，方便后期管理，在组件里只允许出现 dispatch 和 mapGetters，其余的流程都在名为 store 的 vuex 文件夹里进行 可以打印this.$store查看store里的数据 如果store的模块里没有加namespaced，则这个模块的数据是全局的，不需要加路径来引用 v-show，v-if 用哪个？ 权限问题，只要涉及到权限相关的展示无疑要用 v-if 在没有权限限制下根据用户点击的频次选择，频繁切换的使用 v-show，不频繁切换的使用 v-if 尽量保持每个组件 export default {} 内的方法顺序一致 在 webpack 里有个 externals，可以忽略不需要打包的库123456externals: { 'vue': 'Vue', 'vue-router': 'VueRouter', 'vuex': 'Vuex', 'axios': 'axios'} nextTick https://juejin.im/post/5a6fdb846fb9a01cc0268618","link":"/front-end/Vue%E5%9F%BA%E7%A1%80/"},{"title":"利用 charles 和 switchyomega 对被墙网站进行抓包","text":"为了对某国外被墙的网站进行抓包，在网上搜索之后，发现很多说要关闭VPN才能用Charles抓包，明显这是不可能的。于是想到把Charles作为代理服务器，让他连接VPN，然后浏览器把Charles作为代理，即可完成抓包。即：VPN -&gt; Charles -&gt; 浏览器首先在Charles中设置External Proxy Setting，设置为VPN软件在系统内设置的代理，此时Charles已经翻墙。 由于浏览器默认使用系统的代理，所以打开预先在Chrome浏览器内安装的SwitchyOmega，增加如图的配置，即可让浏览器把Charles作为代理，并切换到该配置， 参考：抓包神器之Charles，常用功能都在这里了","link":"/others/capture-banned-website-with-charles-and-switchyomega/"},{"title":"用 CSS 画圆角三角形","text":"1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;&lt;/title&gt;&lt;/head&gt;&lt;style type=\"text/css\"&gt; .line { width: 20px; height: 200px; background: red; position: relative; border-radius: 900px; } .line:after, .line:before { position: absolute; content: ''; width: 20px; background: red; border-radius: 900px; height: 200px; } .line:after { transform: rotate(-60deg); top: -44px; right: -81px; } .line:before { transform: rotate(60deg); top: 46px; right: -80px; } .outer { width: 500px; height: 500px; display: flex; justify-content: center; align-items: center; background: black; } .inner { display: inline-block; width: 0; height: 0; border-style: solid; border-width: 80px 0 90px 150px; position: absolute; border-color: transparent transparent transparent red; top: 10px; right: -150px; }&lt;/style&gt;&lt;body&gt;&lt;div class=\"outer\"&gt; &lt;div class=\"line\"&gt; &lt;span class='inner'&gt;&lt;/span&gt; &lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;","link":"/front-end/corners/"},{"title":"canvas 的外层 Div 为 overflow:hidden 时仍然可见","text":"参考链接answer from stackoverflow","link":"/front-end/canvas-still-visible-when-outer-div-is-set-to-overflow-hidden/"},{"title":"chrome dev tools 的小技巧","text":"看了google官方关于chrome dev tools调试的介绍。发现了两个很好用的功能： restart frame blackbox script，可以避免单步到库文件","link":"/front-end/tricks-in-chrome-dev-tools/"},{"title":"如何用 charles 修改拦截请求的返回值","text":"起因网易云音乐在朋友圈刷了一波推广活动，一进去要输入名字，但是我玩法比较怪，输入的是一些名人的名字，结果被提示“不是你的名字”。于是，把网址放到chrome里，打开dev tool查看，发现提交到服务器进行了验证，而且只要命中名人名字中的两个字，就会被提示报错，你们的算法还挺细致的，哈哈。 比较了一下前端请求验证名字的请求后，服务器返回的验证结果，发现只有最后一个字段不同，猜测前端判断了这个结果，于是想到拦截修改服务器的返回结果，骗过前端程序。 尝试了不同的方法map local 右键点击验证请求，选择save response，保存响应文件 按下⌥⌘L打开Map Local Setting对话框，并增加新的mapping 再次尝试通过前端发送请求，确实修改了响应结果，但是由于保存的响应文件只有body的内容，没有header的内容，在这里报了一个跨域的错误，因此这个方法失败了。 rewrite 按下⌥⌘L打开Rewrite Settings对话框，直接输入需要重写的内容 此时请求之后返回的结果只修改了body部分，别的部分都是原样输出，已经通过了前端程序的验证。 breakpoint 右键点击请求，选择breakpoint，下断点 再次请求，修改响应结果 可以在chrome里看到此时已经是刚刚修改后的响应结果了 碰到的问题 有可能突然抓不到包，可以尝试⇧⌘P关闭macOS proxy，然后再次打开。","link":"/others/how-to-modify-server-response-with-charles/"},{"title":"管理学习进度","text":"为什么想到这个工作以来，为了提升个人能力，一直不断松懈学习。之前看到一篇技术文章，令我感到反思的不是文章的内容，而是作者的学习方法，所以做了这样的思维导图： 需求： 进度规划 每日打卡 提醒 之前的做法 打印日历进行记录（缺点是需要打印，且没有提醒） 利用 numbers 表格记录每日学习内容，完成之后便划掉（需要另外打开软件，无提醒，不方便修改） 利用 wunderlist 记录（无进度） 考虑结合 google cal 进行管理好处 多平台同步，web、mac、iphone等都可以看到 不需要另外的软件 可以利用 week calendar 进行快速标记完成，高亮等操作 步骤 在 google cal 上新建一个日历，以和其他日历内容区隔 下面是 week calendar 的主界面，可以看到我已经配置了一些日历内容 打开右上角的设置 点击工具菜单，可以配置快捷操作，我在这里设置了两个，一个是快速标记完成✅，另外一个是高亮 配置 mac 日历，尝试同步 新增事件时，可以设置每日循环和到期日，这样子可以每天进行打卡","link":"/other/%E7%AE%A1%E7%90%86%E5%AD%A6%E4%B9%A0%E8%BF%9B%E5%BA%A6/"},{"title":"JavaScript 中 require 和 import 的区别","text":"require object is just a shallow copy of module exportstest code as below: 12345678910111213141516171819202122// main.jsvar a = require('./mod')setInterval(() =&gt; { console.log('in main', a.aaa) console.log('in main', a.x) console.log('======');}, 500);// mod.jslet aaa = {a: 3, b: {xx: 1}}let x = 1setInterval(() =&gt; { aaa.a++; aaa.b.xx += 1; x++; console.log('in mod', aaa) console.log('in mod', x)}, 500);module.exports = {aaa: aaa, x: x}; References require，import区别？ Module 的加载实现 Node中没搞明白require和import，你会被坑的很惨","link":"/front-end/something-about-module-in-nodejs/"},{"title":"HTML5 中 video 标签问题总结","text":"problems encounted when start play a video on iOS’s Safari and Wechat browser, it will enter fullscreen but not play in line 1&lt;video controls=\"\" playsInline webkit-playsinline=\"true\" x5-playsinline&gt;&lt;/video&gt; video duration can be achieved when durationchange event fired canplay event will not fired when video loaded on iPhone iOS 11 Safari even I add preload=&quot;auto&quot; prop, but fired on iPad iOS 10 Safari Reference 移动端 HTML5 video 视频播放优化实践 视频H5 video标签最佳实践 移动端 HTML5 video 视频播放实践 New video Policies for iOS 这几年，我在video上踩的坑 为什么要将 Chimee 设计成一个组件化框架？ 视频H5のVideo标签在微信里的坑和技巧 关于HTML5 video标签在安卓版微信浏览器内被强制全屏播放的问题 Creating a cross-browser video player Media formats for HTML audio and video HTML 5 视频/音频参考手册","link":"/front-end/play-with-html5-video-tag/"},{"title":"javascript 学习思维导图","text":"","link":"/front-end/mindmap-for-learning-javascript/"}],"tags":[{"name":"vue","slug":"vue","link":"/tags/vue/"},{"name":"apple","slug":"apple","link":"/tags/apple/"},{"name":"黑苹果","slug":"黑苹果","link":"/tags/%E9%BB%91%E8%8B%B9%E6%9E%9C/"},{"name":"hackintosh","slug":"hackintosh","link":"/tags/hackintosh/"},{"name":"javascript","slug":"javascript","link":"/tags/javascript/"},{"name":"charles","slug":"charles","link":"/tags/charles/"},{"name":"html","slug":"html","link":"/tags/html/"},{"name":"css","slug":"css","link":"/tags/css/"},{"name":"chrome","slug":"chrome","link":"/tags/chrome/"},{"name":"devtools","slug":"devtools","link":"/tags/devtools/"},{"name":"calendar","slug":"calendar","link":"/tags/calendar/"},{"name":"gtd","slug":"gtd","link":"/tags/gtd/"},{"name":"mac","slug":"mac","link":"/tags/mac/"},{"name":"iphone","slug":"iphone","link":"/tags/iphone/"},{"name":"switchyomega","slug":"switchyomega","link":"/tags/switchyomega/"},{"name":"macos","slug":"macos","link":"/tags/macos/"},{"name":"clover","slug":"clover","link":"/tags/clover/"},{"name":"nuxtjs","slug":"nuxtjs","link":"/tags/nuxtjs/"},{"name":"ssr","slug":"ssr","link":"/tags/ssr/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"java","slug":"java","link":"/tags/java/"},{"name":"sql","slug":"sql","link":"/tags/sql/"}],"categories":[{"name":"hardware","slug":"hardware","link":"/categories/hardware/"},{"name":"front-end","slug":"front-end","link":"/categories/front-end/"},{"name":"others","slug":"others","link":"/categories/others/"},{"name":"nuxtjs教程","slug":"front-end/nuxtjs教程","link":"/categories/front-end/nuxtjs%E6%95%99%E7%A8%8B/"},{"name":"python","slug":"python","link":"/categories/python/"},{"name":"other","slug":"other","link":"/categories/other/"}]}